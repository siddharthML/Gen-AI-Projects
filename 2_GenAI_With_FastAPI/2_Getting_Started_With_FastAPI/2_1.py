# Starter code for a simple FastAPI web server serving GPT-4o requests
# Run from terminal using uvicorn 2_1:app --reload

from fastapi import FastAPI
import os
from langchain_openai import AzureChatOpenAI

app = FastAPI()

# Azure OpenAI Details (use environment variables or other secure storage):
os.environ["AZURE_OPENAI_API_KEY"] = "your_actual_api_key_here"  # Replace with your actual key
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://your.azure.endpoint.here/"
os.environ["AZURE_OPENAI_API_VERSION"] = "2024-05-01-preview"  # Ensure the correct API version

# Setup Azure OpenAI connection
model = AzureChatOpenAI(
    model="gpt-4o",  # Ensure this matches your deployed model
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION")
)

@app.get("/")
def root_controller():
    """
    Root endpoint to check server health status.
    """
    return {"status": "healthy"}

@app.get("/chat")
def chat_controller(prompt: str = "Inspire me"):
    """
    Chat endpoint that takes a prompt and returns a response generated by Azure OpenAI GPT-4o model.

    Args:
        prompt (str): The prompt for the model to generate a response.

    Returns:
        dict: A dictionary containing the generated statement.
    """
    # Generate response using the AzureChatOpenAI model
    response = model(messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": prompt},
    ])
    # Extract response content
    statement = response.content
    return {"statement": statement}