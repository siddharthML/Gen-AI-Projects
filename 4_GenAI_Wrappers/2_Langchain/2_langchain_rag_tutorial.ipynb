{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain RAG Tutorial\n",
    "\n",
    "https://www.youtube.com/watch?v=yF9kGESAi3M\n",
    "\n",
    "![RAG_1](RAG_1.JPG)\n",
    "\n",
    "![RAG_2](RAG_2.JPG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-core\n",
    "# !pip install langchain==0.3.20\n",
    "# !pip install langchain-community==0.3.19\n",
    "# !pip install langchain-openai==0.3.7\n",
    "# !pip install langchain-text-splitters==0.3.6\n",
    "# !pip install langchain-chroma\n",
    "# !pip install sentence-transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = os.getenv(\"AZURE_OPENAI_API_VERSION\")  # Use the correct API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup azure openai connection\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a. RAG Basics - Setup Vector Store and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.path.abspath(\"\")\n",
    "file_path = os.path.join(current_dir, \"books\", \"AI_Engineering.txt\")\n",
    "persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1384, which is longer than the specified 1000\n",
      "Created a chunk of size 1145, which is longer than the specified 1000\n",
      "Created a chunk of size 1024, which is longer than the specified 1000\n",
      "Created a chunk of size 1686, which is longer than the specified 1000\n",
      "Created a chunk of size 1771, which is longer than the specified 1000\n",
      "Created a chunk of size 1054, which is longer than the specified 1000\n",
      "Created a chunk of size 1109, which is longer than the specified 1000\n",
      "Created a chunk of size 1151, which is longer than the specified 1000\n",
      "Created a chunk of size 1458, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n",
      "Created a chunk of size 2743, which is longer than the specified 1000\n",
      "Created a chunk of size 2103, which is longer than the specified 1000\n",
      "Created a chunk of size 2328, which is longer than the specified 1000\n",
      "Created a chunk of size 2424, which is longer than the specified 1000\n",
      "Created a chunk of size 1636, which is longer than the specified 1000\n",
      "Created a chunk of size 1263, which is longer than the specified 1000\n",
      "Created a chunk of size 1370, which is longer than the specified 1000\n",
      "Created a chunk of size 1494, which is longer than the specified 1000\n",
      "Created a chunk of size 1456, which is longer than the specified 1000\n",
      "Created a chunk of size 1627, which is longer than the specified 1000\n",
      "Created a chunk of size 1677, which is longer than the specified 1000\n",
      "Created a chunk of size 1684, which is longer than the specified 1000\n",
      "Created a chunk of size 1761, which is longer than the specified 1000\n",
      "Created a chunk of size 2491, which is longer than the specified 1000\n",
      "Created a chunk of size 1046, which is longer than the specified 1000\n",
      "Created a chunk of size 1500, which is longer than the specified 1000\n",
      "Created a chunk of size 1358, which is longer than the specified 1000\n",
      "Created a chunk of size 1377, which is longer than the specified 1000\n",
      "Created a chunk of size 1215, which is longer than the specified 1000\n",
      "Created a chunk of size 1741, which is longer than the specified 1000\n",
      "Created a chunk of size 2474, which is longer than the specified 1000\n",
      "Created a chunk of size 1279, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1839, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 1464, which is longer than the specified 1000\n",
      "Created a chunk of size 2155, which is longer than the specified 1000\n",
      "Created a chunk of size 2123, which is longer than the specified 1000\n",
      "Created a chunk of size 1326, which is longer than the specified 1000\n",
      "Created a chunk of size 1574, which is longer than the specified 1000\n",
      "Created a chunk of size 1103, which is longer than the specified 1000\n",
      "Created a chunk of size 1593, which is longer than the specified 1000\n",
      "Created a chunk of size 2252, which is longer than the specified 1000\n",
      "Created a chunk of size 1077, which is longer than the specified 1000\n",
      "Created a chunk of size 1658, which is longer than the specified 1000\n",
      "Created a chunk of size 1135, which is longer than the specified 1000\n",
      "Created a chunk of size 2176, which is longer than the specified 1000\n",
      "Created a chunk of size 1207, which is longer than the specified 1000\n",
      "Created a chunk of size 1690, which is longer than the specified 1000\n",
      "Created a chunk of size 1359, which is longer than the specified 1000\n",
      "Created a chunk of size 1311, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1404, which is longer than the specified 1000\n",
      "Created a chunk of size 1100, which is longer than the specified 1000\n",
      "Created a chunk of size 1696, which is longer than the specified 1000\n",
      "Created a chunk of size 1890, which is longer than the specified 1000\n",
      "Created a chunk of size 1441, which is longer than the specified 1000\n",
      "Created a chunk of size 1458, which is longer than the specified 1000\n",
      "Created a chunk of size 2038, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1856, which is longer than the specified 1000\n",
      "Created a chunk of size 1475, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistent directory does not exist. Intializing vector store..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1394, which is longer than the specified 1000\n",
      "Created a chunk of size 1160, which is longer than the specified 1000\n",
      "Created a chunk of size 1837, which is longer than the specified 1000\n",
      "Created a chunk of size 1779, which is longer than the specified 1000\n",
      "Created a chunk of size 2066, which is longer than the specified 1000\n",
      "Created a chunk of size 2130, which is longer than the specified 1000\n",
      "Created a chunk of size 2013, which is longer than the specified 1000\n",
      "Created a chunk of size 1274, which is longer than the specified 1000\n",
      "Created a chunk of size 1259, which is longer than the specified 1000\n",
      "Created a chunk of size 2200, which is longer than the specified 1000\n",
      "Created a chunk of size 1939, which is longer than the specified 1000\n",
      "Created a chunk of size 1305, which is longer than the specified 1000\n",
      "Created a chunk of size 2099, which is longer than the specified 1000\n",
      "Created a chunk of size 2171, which is longer than the specified 1000\n",
      "Created a chunk of size 1040, which is longer than the specified 1000\n",
      "Created a chunk of size 1549, which is longer than the specified 1000\n",
      "Created a chunk of size 1126, which is longer than the specified 1000\n",
      "Created a chunk of size 1608, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1413, which is longer than the specified 1000\n",
      "Created a chunk of size 1727, which is longer than the specified 1000\n",
      "Created a chunk of size 1167, which is longer than the specified 1000\n",
      "Created a chunk of size 1892, which is longer than the specified 1000\n",
      "Created a chunk of size 1649, which is longer than the specified 1000\n",
      "Created a chunk of size 1574, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 2202, which is longer than the specified 1000\n",
      "Created a chunk of size 1245, which is longer than the specified 1000\n",
      "Created a chunk of size 1809, which is longer than the specified 1000\n",
      "Created a chunk of size 1212, which is longer than the specified 1000\n",
      "Created a chunk of size 1854, which is longer than the specified 1000\n",
      "Created a chunk of size 2304, which is longer than the specified 1000\n",
      "Created a chunk of size 1633, which is longer than the specified 1000\n",
      "Created a chunk of size 1618, which is longer than the specified 1000\n",
      "Created a chunk of size 2567, which is longer than the specified 1000\n",
      "Created a chunk of size 1076, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1592, which is longer than the specified 1000\n",
      "Created a chunk of size 1113, which is longer than the specified 1000\n",
      "Created a chunk of size 1065, which is longer than the specified 1000\n",
      "Created a chunk of size 1331, which is longer than the specified 1000\n",
      "Created a chunk of size 2399, which is longer than the specified 1000\n",
      "Created a chunk of size 1255, which is longer than the specified 1000\n",
      "Created a chunk of size 1318, which is longer than the specified 1000\n",
      "Created a chunk of size 2691, which is longer than the specified 1000\n",
      "Created a chunk of size 1079, which is longer than the specified 1000\n",
      "Created a chunk of size 1774, which is longer than the specified 1000\n",
      "Created a chunk of size 1350, which is longer than the specified 1000\n",
      "Created a chunk of size 2331, which is longer than the specified 1000\n",
      "Created a chunk of size 1306, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 2198, which is longer than the specified 1000\n",
      "Created a chunk of size 1851, which is longer than the specified 1000\n",
      "Created a chunk of size 1390, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1443, which is longer than the specified 1000\n",
      "Created a chunk of size 1558, which is longer than the specified 1000\n",
      "Created a chunk of size 1757, which is longer than the specified 1000\n",
      "Created a chunk of size 1395, which is longer than the specified 1000\n",
      "Created a chunk of size 2180, which is longer than the specified 1000\n",
      "Created a chunk of size 1178, which is longer than the specified 1000\n",
      "Created a chunk of size 1623, which is longer than the specified 1000\n",
      "Created a chunk of size 1491, which is longer than the specified 1000\n",
      "Created a chunk of size 2047, which is longer than the specified 1000\n",
      "Created a chunk of size 1782, which is longer than the specified 1000\n",
      "Created a chunk of size 2479, which is longer than the specified 1000\n",
      "Created a chunk of size 1127, which is longer than the specified 1000\n",
      "Created a chunk of size 1491, which is longer than the specified 1000\n",
      "Created a chunk of size 2384, which is longer than the specified 1000\n",
      "Created a chunk of size 1620, which is longer than the specified 1000\n",
      "Created a chunk of size 1530, which is longer than the specified 1000\n",
      "Created a chunk of size 2589, which is longer than the specified 1000\n",
      "Created a chunk of size 2147, which is longer than the specified 1000\n",
      "Created a chunk of size 2552, which is longer than the specified 1000\n",
      "Created a chunk of size 2739, which is longer than the specified 1000\n",
      "Created a chunk of size 1280, which is longer than the specified 1000\n",
      "Created a chunk of size 1305, which is longer than the specified 1000\n",
      "Created a chunk of size 1039, which is longer than the specified 1000\n",
      "Created a chunk of size 1035, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 2030, which is longer than the specified 1000\n",
      "Created a chunk of size 1438, which is longer than the specified 1000\n",
      "Created a chunk of size 1135, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1388, which is longer than the specified 1000\n",
      "Created a chunk of size 1401, which is longer than the specified 1000\n",
      "Created a chunk of size 1464, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1234, which is longer than the specified 1000\n",
      "Created a chunk of size 1949, which is longer than the specified 1000\n",
      "Created a chunk of size 1317, which is longer than the specified 1000\n",
      "Created a chunk of size 1138, which is longer than the specified 1000\n",
      "Created a chunk of size 1577, which is longer than the specified 1000\n",
      "Created a chunk of size 1286, which is longer than the specified 1000\n",
      "Created a chunk of size 1308, which is longer than the specified 1000\n",
      "Created a chunk of size 1278, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 2249, which is longer than the specified 1000\n",
      "Created a chunk of size 1925, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 1237, which is longer than the specified 1000\n",
      "Created a chunk of size 1380, which is longer than the specified 1000\n",
      "Created a chunk of size 1550, which is longer than the specified 1000\n",
      "Created a chunk of size 1811, which is longer than the specified 1000\n",
      "Created a chunk of size 1255, which is longer than the specified 1000\n",
      "Created a chunk of size 2011, which is longer than the specified 1000\n",
      "Created a chunk of size 1392, which is longer than the specified 1000\n",
      "Created a chunk of size 2077, which is longer than the specified 1000\n",
      "Created a chunk of size 2698, which is longer than the specified 1000\n",
      "Created a chunk of size 1826, which is longer than the specified 1000\n",
      "Created a chunk of size 2263, which is longer than the specified 1000\n",
      "Created a chunk of size 1024, which is longer than the specified 1000\n",
      "Created a chunk of size 1013, which is longer than the specified 1000\n",
      "Created a chunk of size 2167, which is longer than the specified 1000\n",
      "Created a chunk of size 1724, which is longer than the specified 1000\n",
      "Created a chunk of size 1240, which is longer than the specified 1000\n",
      "Created a chunk of size 1392, which is longer than the specified 1000\n",
      "Created a chunk of size 1366, which is longer than the specified 1000\n",
      "Created a chunk of size 1029, which is longer than the specified 1000\n",
      "Created a chunk of size 1105, which is longer than the specified 1000\n",
      "Created a chunk of size 1242, which is longer than the specified 1000\n",
      "Created a chunk of size 1189, which is longer than the specified 1000\n",
      "Created a chunk of size 1130, which is longer than the specified 1000\n",
      "Created a chunk of size 1324, which is longer than the specified 1000\n",
      "Created a chunk of size 1146, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 1329, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1859, which is longer than the specified 1000\n",
      "Created a chunk of size 1482, which is longer than the specified 1000\n",
      "Created a chunk of size 1351, which is longer than the specified 1000\n",
      "Created a chunk of size 1171, which is longer than the specified 1000\n",
      "Created a chunk of size 1327, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1127, which is longer than the specified 1000\n",
      "Created a chunk of size 1074, which is longer than the specified 1000\n",
      "Created a chunk of size 1646, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 2561, which is longer than the specified 1000\n",
      "Created a chunk of size 1226, which is longer than the specified 1000\n",
      "Created a chunk of size 1897, which is longer than the specified 1000\n",
      "Created a chunk of size 1203, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n",
      "Created a chunk of size 1512, which is longer than the specified 1000\n",
      "Created a chunk of size 1059, which is longer than the specified 1000\n",
      "Created a chunk of size 1202, which is longer than the specified 1000\n",
      "Created a chunk of size 1442, which is longer than the specified 1000\n",
      "Created a chunk of size 1601, which is longer than the specified 1000\n",
      "Created a chunk of size 2023, which is longer than the specified 1000\n",
      "Created a chunk of size 1729, which is longer than the specified 1000\n",
      "Created a chunk of size 2017, which is longer than the specified 1000\n",
      "Created a chunk of size 1798, which is longer than the specified 1000\n",
      "Created a chunk of size 2495, which is longer than the specified 1000\n",
      "Created a chunk of size 2379, which is longer than the specified 1000\n",
      "Created a chunk of size 2493, which is longer than the specified 1000\n",
      "Created a chunk of size 2147, which is longer than the specified 1000\n",
      "Created a chunk of size 1867, which is longer than the specified 1000\n",
      "Created a chunk of size 1840, which is longer than the specified 1000\n",
      "Created a chunk of size 2879, which is longer than the specified 1000\n",
      "Created a chunk of size 1190, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1873, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1523, which is longer than the specified 1000\n",
      "Created a chunk of size 1219, which is longer than the specified 1000\n",
      "Created a chunk of size 1715, which is longer than the specified 1000\n",
      "Created a chunk of size 2484, which is longer than the specified 1000\n",
      "Created a chunk of size 2362, which is longer than the specified 1000\n",
      "Created a chunk of size 2184, which is longer than the specified 1000\n",
      "Created a chunk of size 1288, which is longer than the specified 1000\n",
      "Created a chunk of size 1829, which is longer than the specified 1000\n",
      "Created a chunk of size 2540, which is longer than the specified 1000\n",
      "Created a chunk of size 1779, which is longer than the specified 1000\n",
      "Created a chunk of size 1306, which is longer than the specified 1000\n",
      "Created a chunk of size 1156, which is longer than the specified 1000\n",
      "Created a chunk of size 1329, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1743, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 2011, which is longer than the specified 1000\n",
      "Created a chunk of size 1497, which is longer than the specified 1000\n",
      "Created a chunk of size 2800, which is longer than the specified 1000\n",
      "Created a chunk of size 1952, which is longer than the specified 1000\n",
      "Created a chunk of size 2899, which is longer than the specified 1000\n",
      "Created a chunk of size 1850, which is longer than the specified 1000\n",
      "Created a chunk of size 1487, which is longer than the specified 1000\n",
      "Created a chunk of size 1368, which is longer than the specified 1000\n",
      "Created a chunk of size 1239, which is longer than the specified 1000\n",
      "Created a chunk of size 2946, which is longer than the specified 1000\n",
      "Created a chunk of size 2047, which is longer than the specified 1000\n",
      "Created a chunk of size 2924, which is longer than the specified 1000\n",
      "Created a chunk of size 1093, which is longer than the specified 1000\n",
      "Created a chunk of size 1007, which is longer than the specified 1000\n",
      "Created a chunk of size 1237, which is longer than the specified 1000\n",
      "Created a chunk of size 1893, which is longer than the specified 1000\n",
      "Created a chunk of size 1320, which is longer than the specified 1000\n",
      "Created a chunk of size 1655, which is longer than the specified 1000\n",
      "Created a chunk of size 1729, which is longer than the specified 1000\n",
      "Created a chunk of size 1794, which is longer than the specified 1000\n",
      "Created a chunk of size 1446, which is longer than the specified 1000\n",
      "Created a chunk of size 1148, which is longer than the specified 1000\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 1879, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 1396, which is longer than the specified 1000\n",
      "Created a chunk of size 1021, which is longer than the specified 1000\n",
      "Created a chunk of size 1087, which is longer than the specified 1000\n",
      "Created a chunk of size 1490, which is longer than the specified 1000\n",
      "Created a chunk of size 1916, which is longer than the specified 1000\n",
      "Created a chunk of size 1062, which is longer than the specified 1000\n",
      "Created a chunk of size 1033, which is longer than the specified 1000\n",
      "Created a chunk of size 1262, which is longer than the specified 1000\n",
      "Created a chunk of size 2013, which is longer than the specified 1000\n",
      "Created a chunk of size 1430, which is longer than the specified 1000\n",
      "Created a chunk of size 1756, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 1531, which is longer than the specified 1000\n",
      "Created a chunk of size 1608, which is longer than the specified 1000\n",
      "Created a chunk of size 2222, which is longer than the specified 1000\n",
      "Created a chunk of size 2512, which is longer than the specified 1000\n",
      "Created a chunk of size 1803, which is longer than the specified 1000\n",
      "Created a chunk of size 1166, which is longer than the specified 1000\n",
      "Created a chunk of size 1545, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1004, which is longer than the specified 1000\n",
      "Created a chunk of size 1202, which is longer than the specified 1000\n",
      "Created a chunk of size 1271, which is longer than the specified 1000\n",
      "Created a chunk of size 1918, which is longer than the specified 1000\n",
      "Created a chunk of size 1151, which is longer than the specified 1000\n",
      "Created a chunk of size 1122, which is longer than the specified 1000\n",
      "Created a chunk of size 1719, which is longer than the specified 1000\n",
      "Created a chunk of size 2124, which is longer than the specified 1000\n",
      "Created a chunk of size 1602, which is longer than the specified 1000\n",
      "Created a chunk of size 2990, which is longer than the specified 1000\n",
      "Created a chunk of size 2297, which is longer than the specified 1000\n",
      "Created a chunk of size 1734, which is longer than the specified 1000\n",
      "Created a chunk of size 2973, which is longer than the specified 1000\n",
      "Created a chunk of size 1925, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1252, which is longer than the specified 1000\n",
      "Created a chunk of size 1415, which is longer than the specified 1000\n",
      "Created a chunk of size 1386, which is longer than the specified 1000\n",
      "Created a chunk of size 2372, which is longer than the specified 1000\n",
      "Created a chunk of size 1655, which is longer than the specified 1000\n",
      "Created a chunk of size 1617, which is longer than the specified 1000\n",
      "Created a chunk of size 2109, which is longer than the specified 1000\n",
      "Created a chunk of size 2022, which is longer than the specified 1000\n",
      "Created a chunk of size 1745, which is longer than the specified 1000\n",
      "Created a chunk of size 1819, which is longer than the specified 1000\n",
      "Created a chunk of size 2194, which is longer than the specified 1000\n",
      "Created a chunk of size 2425, which is longer than the specified 1000\n",
      "Created a chunk of size 1968, which is longer than the specified 1000\n",
      "Created a chunk of size 1837, which is longer than the specified 1000\n",
      "Created a chunk of size 1609, which is longer than the specified 1000\n",
      "Created a chunk of size 2924, which is longer than the specified 1000\n",
      "Created a chunk of size 1244, which is longer than the specified 1000\n",
      "Created a chunk of size 2546, which is longer than the specified 1000\n",
      "Created a chunk of size 1261, which is longer than the specified 1000\n",
      "Created a chunk of size 1595, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1811, which is longer than the specified 1000\n",
      "Created a chunk of size 1957, which is longer than the specified 1000\n",
      "Created a chunk of size 2436, which is longer than the specified 1000\n",
      "Created a chunk of size 1616, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1164, which is longer than the specified 1000\n",
      "Created a chunk of size 1037, which is longer than the specified 1000\n",
      "Created a chunk of size 1669, which is longer than the specified 1000\n",
      "Created a chunk of size 1921, which is longer than the specified 1000\n",
      "Created a chunk of size 1401, which is longer than the specified 1000\n",
      "Created a chunk of size 1218, which is longer than the specified 1000\n",
      "Created a chunk of size 2324, which is longer than the specified 1000\n",
      "Created a chunk of size 1369, which is longer than the specified 1000\n",
      "Created a chunk of size 1109, which is longer than the specified 1000\n",
      "Created a chunk of size 1973, which is longer than the specified 1000\n",
      "Created a chunk of size 1123, which is longer than the specified 1000\n",
      "Created a chunk of size 1209, which is longer than the specified 1000\n",
      "Created a chunk of size 1811, which is longer than the specified 1000\n",
      "Created a chunk of size 2768, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1583, which is longer than the specified 1000\n",
      "Created a chunk of size 1442, which is longer than the specified 1000\n",
      "Created a chunk of size 2397, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 1345, which is longer than the specified 1000\n",
      "Created a chunk of size 1516, which is longer than the specified 1000\n",
      "Created a chunk of size 2390, which is longer than the specified 1000\n",
      "Created a chunk of size 1120, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1374, which is longer than the specified 1000\n",
      "Created a chunk of size 1273, which is longer than the specified 1000\n",
      "Created a chunk of size 2178, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 1555, which is longer than the specified 1000\n",
      "Created a chunk of size 2462, which is longer than the specified 1000\n",
      "Created a chunk of size 1211, which is longer than the specified 1000\n",
      "Created a chunk of size 1013, which is longer than the specified 1000\n",
      "Created a chunk of size 1333, which is longer than the specified 1000\n",
      "Created a chunk of size 1942, which is longer than the specified 1000\n",
      "Created a chunk of size 2295, which is longer than the specified 1000\n",
      "Created a chunk of size 2500, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 2868, which is longer than the specified 1000\n",
      "Created a chunk of size 1267, which is longer than the specified 1000\n",
      "Created a chunk of size 2179, which is longer than the specified 1000\n",
      "Created a chunk of size 1863, which is longer than the specified 1000\n",
      "Created a chunk of size 1387, which is longer than the specified 1000\n",
      "Created a chunk of size 1039, which is longer than the specified 1000\n",
      "Created a chunk of size 2259, which is longer than the specified 1000\n",
      "Created a chunk of size 2160, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 2292, which is longer than the specified 1000\n",
      "Created a chunk of size 1566, which is longer than the specified 1000\n",
      "Created a chunk of size 1095, which is longer than the specified 1000\n",
      "Created a chunk of size 1507, which is longer than the specified 1000\n",
      "Created a chunk of size 1592, which is longer than the specified 1000\n",
      "Created a chunk of size 1725, which is longer than the specified 1000\n",
      "Created a chunk of size 1096, which is longer than the specified 1000\n",
      "Created a chunk of size 1117, which is longer than the specified 1000\n",
      "Created a chunk of size 1247, which is longer than the specified 1000\n",
      "Created a chunk of size 1248, which is longer than the specified 1000\n",
      "Created a chunk of size 1028, which is longer than the specified 1000\n",
      "Created a chunk of size 1081, which is longer than the specified 1000\n",
      "Created a chunk of size 2234, which is longer than the specified 1000\n",
      "Created a chunk of size 1110, which is longer than the specified 1000\n",
      "Created a chunk of size 1947, which is longer than the specified 1000\n",
      "Created a chunk of size 1472, which is longer than the specified 1000\n",
      "Created a chunk of size 1038, which is longer than the specified 1000\n",
      "Created a chunk of size 1294, which is longer than the specified 1000\n",
      "Created a chunk of size 1490, which is longer than the specified 1000\n",
      "Created a chunk of size 1476, which is longer than the specified 1000\n",
      "Created a chunk of size 1494, which is longer than the specified 1000\n",
      "Created a chunk of size 1180, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1050, which is longer than the specified 1000\n",
      "Created a chunk of size 1363, which is longer than the specified 1000\n",
      "Created a chunk of size 1172, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1217, which is longer than the specified 1000\n",
      "Created a chunk of size 1199, which is longer than the specified 1000\n",
      "Created a chunk of size 1398, which is longer than the specified 1000\n",
      "Created a chunk of size 1312, which is longer than the specified 1000\n",
      "Created a chunk of size 1193, which is longer than the specified 1000\n",
      "Created a chunk of size 1147, which is longer than the specified 1000\n",
      "Created a chunk of size 1153, which is longer than the specified 1000\n",
      "Created a chunk of size 1858, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Document Chunk Information-----\n",
      "Number of document chunks: 1143\n",
      "Sample chunk: \n",
      "AI Engineering\n",
      "Building Applications\n",
      "with Foundation Models\n",
      "\n",
      "Chip Huyen\n",
      "\n",
      "\f“This book offers a comprehensive, well-structured guide to the essential\n",
      "aspects of building generative AI systems. A must-read for any professional\n",
      "looking to scale AI across the enterprise.”\n",
      "Vittorio Cretella, former global CIO at P&G and Mars\n",
      "\n",
      "“Chip Huyen gets generative AI. She is a remarkable teacher and writer\n",
      "whose work has been instrumental in helping teams bring AI into production.\n",
      "Drawing on her deep expertise, AI Engineering is a comprehensive and\n",
      "holistic guide to building generative AI applications in production.”\n",
      "\t\t Luke Metz, cocreator of ChatGPT, former research manager at OpenAI\n",
      "\n",
      "\n",
      "---Create embeddings---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Siddharth\\.conda\\envs\\repgpt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Siddharth\\.conda\\envs\\repgpt\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Siddharth\\.cache\\huggingface\\hub\\models--sentence-transformers--multi-qa-mpnet-base-dot-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Finished creating embeddings----\n",
      "n----Creating vector store----\n",
      "\n",
      "---Finished creating vector store----\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script initializes a Chroma vector store if it does not already exist.\n",
    "It reads text from a specified file, splits it into chunks, creates embeddings,\n",
    "and then creates and persists the vector store.\n",
    "\"\"\"\n",
    "\n",
    "# Check if Chroma vector store already exists\n",
    "if not os.path.exists(persistent_directory):\n",
    "    print(\"Persistent directory does not exist. Initializing vector store...\")\n",
    "\n",
    "    # Ensure the text file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"The file {file_path} does not exist. Please check the path.\"\n",
    "        )\n",
    "\n",
    "    # Read the text content from the file\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split document into chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Display info about split documents\n",
    "    print(\"\\n----Document Chunk Information-----\")\n",
    "    print(f\"Number of document chunks: {len(docs)}\")\n",
    "    print(f\"Sample chunk: \\n{docs[0].page_content}\\n\")\n",
    "\n",
    "    # Create embeddings\n",
    "    print(\"\\n---Create embeddings---\")\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")  # Update to any valid embedding model\n",
    "    print(\"\\n-----Finished creating embeddings----\")\n",
    "\n",
    "    # Create the vector store and persist it automatically\n",
    "    print(\"\\n----Creating vector store----\")\n",
    "    db = Chroma.from_documents(docs, embeddings, persist_directory=persistent_directory)\n",
    "    print(\"\\n---Finished creating vector store----\")\n",
    "\n",
    "else:\n",
    "    print(\"Vector store already exists. No need to initialize.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b - RAG Basics - Do querying and retrieve chunks from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the persistent directory\n",
    "import os\n",
    "current_dir = os.path.abspath(\"\")\n",
    "persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding model\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth\\AppData\\Local\\Temp\\ipykernel_42544\\572194542.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=persistent_directory,\n"
     ]
    }
   ],
   "source": [
    "# Loading existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's question\n",
    "query = \"What is model distillation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the relevant documents based on query\n",
    "retriever = db.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs={\"k\":3},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents ---\n",
      "Document 1:\n",
      "Model Distillation\n",
      "Model distillation (also called knowledge distillation) is a method in which a small\n",
      "model (student) is trained to mimic a larger model (teacher) (Hinton et al., 2015).\n",
      "The knowledge of the big model is distilled into the small model, hence the term dis‐\n",
      "tillation.\n",
      "Traditionally, the goal of model distillation is to produce smaller models for deploy‐\n",
      "ment. Deploying a big model can be resource-intensive. Distillation can produce a\n",
      "smaller, faster student model that retains performance comparable to the teacher. For\n",
      "example, DistilBERT, a model distilled from BERT, reduces the size of a BERT model\n",
      "by 40% while retaining 97% of its language comprehension capabilities and being\n",
      "60% faster (Sanh et al., 2019).\n",
      "The student model can be trained from scratch like DistilBERT or finetuned from a\n",
      "pre-trained model like Alpaca. In 2023, Taori et al. finetuned Llama-7B, the 7-billionparameter version of Llama, on examples generated by text-davinci-003, a 175billion-parameter model. The resulting model, Alpaca, behaves similarly to textdavinci-003, while being 4% the size of the teacher model.\n",
      "Not all models can be distilled. Many model licenses prohibit using\n",
      "their outputs to train other models, particularly to train competing\n",
      "models.\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 2:\n",
      "tion, as discussed in Chapter 2.\n",
      "\n",
      "Prompt Engineering Best Practices\n",
      "\n",
      "|\n",
      "\n",
      "223\n",
      "\n",
      "\fYou can either provide the model with the necessary context or give it tools to gather\n",
      "context. The process of gathering necessary context for a given query is called context\n",
      "construction. Context construction tools include data retrieval, such as in a RAG\n",
      "pipeline, and web search. These tools are discussed in Chapter 6.\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 3:\n",
      "Term-based retrieval\n",
      "Given a query, the most straightforward way to find relevant documents is with key‐\n",
      "words. Some people call this approach lexical retrieval. For example, given the query\n",
      "“AI engineering”, the model will retrieve all the documents that contain “AI engi‐\n",
      "neering”. However, this approach has two problems:\n",
      "• Many documents might contain the given term, and your model might not have\n",
      "sufficient context space to include all of them as context. A heuristic is to include\n",
      "the documents that contain the term the greatest number of times. The assump‐\n",
      "tion is that the more a term appears in a document, the more relevant this docu‐\n",
      "ment is to this term. The number of times a term appears in a document is called\n",
      "term frequency (TF).\n",
      "• A prompt can be long and contain many terms. Some are more important than\n",
      "others. For example, the prompt “Easy-to-follow recipes for Vietnamese food to\n",
      "cook at home” contains nine terms: easy-to-follow, recipes, for, vietnamese, food,\n",
      "258\n",
      "\n",
      "|\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the relevant results with metadata\n",
    "print(\"\\n--- Relevant Documents ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "    if doc.metadata:\n",
    "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a. RAG basics with metadata and multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the text files and the persistent directory\n",
    "current_dir = os.path.abspath(\"\")\n",
    "books_dir = os.path.join(current_dir, \"books\") # Earlier he just described one file with an extra argument. Now its entire folder.\n",
    "db_dir = os.path.join(current_dir, \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata\") # Earlier it was just chroma but now its chroma with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books directory: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\n",
      "Persistent directory: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\db\\chroma_db_with_metadata\n"
     ]
    }
   ],
   "source": [
    "print(f\"Books directory: {books_dir}\")\n",
    "print(f\"Persistent directory: {persistent_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1384, which is longer than the specified 1000\n",
      "Created a chunk of size 1145, which is longer than the specified 1000\n",
      "Created a chunk of size 1024, which is longer than the specified 1000\n",
      "Created a chunk of size 1686, which is longer than the specified 1000\n",
      "Created a chunk of size 1771, which is longer than the specified 1000\n",
      "Created a chunk of size 1054, which is longer than the specified 1000\n",
      "Created a chunk of size 1109, which is longer than the specified 1000\n",
      "Created a chunk of size 1151, which is longer than the specified 1000\n",
      "Created a chunk of size 1458, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n",
      "Created a chunk of size 2743, which is longer than the specified 1000\n",
      "Created a chunk of size 2103, which is longer than the specified 1000\n",
      "Created a chunk of size 2328, which is longer than the specified 1000\n",
      "Created a chunk of size 2424, which is longer than the specified 1000\n",
      "Created a chunk of size 1636, which is longer than the specified 1000\n",
      "Created a chunk of size 1263, which is longer than the specified 1000\n",
      "Created a chunk of size 1370, which is longer than the specified 1000\n",
      "Created a chunk of size 1494, which is longer than the specified 1000\n",
      "Created a chunk of size 1456, which is longer than the specified 1000\n",
      "Created a chunk of size 1627, which is longer than the specified 1000\n",
      "Created a chunk of size 1677, which is longer than the specified 1000\n",
      "Created a chunk of size 1684, which is longer than the specified 1000\n",
      "Created a chunk of size 1761, which is longer than the specified 1000\n",
      "Created a chunk of size 2491, which is longer than the specified 1000\n",
      "Created a chunk of size 1046, which is longer than the specified 1000\n",
      "Created a chunk of size 1500, which is longer than the specified 1000\n",
      "Created a chunk of size 1358, which is longer than the specified 1000\n",
      "Created a chunk of size 1377, which is longer than the specified 1000\n",
      "Created a chunk of size 1215, which is longer than the specified 1000\n",
      "Created a chunk of size 1741, which is longer than the specified 1000\n",
      "Created a chunk of size 2474, which is longer than the specified 1000\n",
      "Created a chunk of size 1279, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1839, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 1464, which is longer than the specified 1000\n",
      "Created a chunk of size 2155, which is longer than the specified 1000\n",
      "Created a chunk of size 2123, which is longer than the specified 1000\n",
      "Created a chunk of size 1326, which is longer than the specified 1000\n",
      "Created a chunk of size 1574, which is longer than the specified 1000\n",
      "Created a chunk of size 1103, which is longer than the specified 1000\n",
      "Created a chunk of size 1593, which is longer than the specified 1000\n",
      "Created a chunk of size 2252, which is longer than the specified 1000\n",
      "Created a chunk of size 1077, which is longer than the specified 1000\n",
      "Created a chunk of size 1658, which is longer than the specified 1000\n",
      "Created a chunk of size 1135, which is longer than the specified 1000\n",
      "Created a chunk of size 2176, which is longer than the specified 1000\n",
      "Created a chunk of size 1207, which is longer than the specified 1000\n",
      "Created a chunk of size 1690, which is longer than the specified 1000\n",
      "Created a chunk of size 1359, which is longer than the specified 1000\n",
      "Created a chunk of size 1311, which is longer than the specified 1000\n",
      "Created a chunk of size 1404, which is longer than the specified 1000\n",
      "Created a chunk of size 1100, which is longer than the specified 1000\n",
      "Created a chunk of size 1696, which is longer than the specified 1000\n",
      "Created a chunk of size 1890, which is longer than the specified 1000\n",
      "Created a chunk of size 1441, which is longer than the specified 1000\n",
      "Created a chunk of size 1458, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistent directory does not exist. Initializing vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2038, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1856, which is longer than the specified 1000\n",
      "Created a chunk of size 1475, which is longer than the specified 1000\n",
      "Created a chunk of size 1394, which is longer than the specified 1000\n",
      "Created a chunk of size 1160, which is longer than the specified 1000\n",
      "Created a chunk of size 1837, which is longer than the specified 1000\n",
      "Created a chunk of size 1779, which is longer than the specified 1000\n",
      "Created a chunk of size 2066, which is longer than the specified 1000\n",
      "Created a chunk of size 2130, which is longer than the specified 1000\n",
      "Created a chunk of size 2013, which is longer than the specified 1000\n",
      "Created a chunk of size 1274, which is longer than the specified 1000\n",
      "Created a chunk of size 1259, which is longer than the specified 1000\n",
      "Created a chunk of size 2200, which is longer than the specified 1000\n",
      "Created a chunk of size 1939, which is longer than the specified 1000\n",
      "Created a chunk of size 1305, which is longer than the specified 1000\n",
      "Created a chunk of size 2099, which is longer than the specified 1000\n",
      "Created a chunk of size 2171, which is longer than the specified 1000\n",
      "Created a chunk of size 1040, which is longer than the specified 1000\n",
      "Created a chunk of size 1549, which is longer than the specified 1000\n",
      "Created a chunk of size 1126, which is longer than the specified 1000\n",
      "Created a chunk of size 1608, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1413, which is longer than the specified 1000\n",
      "Created a chunk of size 1727, which is longer than the specified 1000\n",
      "Created a chunk of size 1167, which is longer than the specified 1000\n",
      "Created a chunk of size 1892, which is longer than the specified 1000\n",
      "Created a chunk of size 1649, which is longer than the specified 1000\n",
      "Created a chunk of size 1574, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 2202, which is longer than the specified 1000\n",
      "Created a chunk of size 1245, which is longer than the specified 1000\n",
      "Created a chunk of size 1809, which is longer than the specified 1000\n",
      "Created a chunk of size 1212, which is longer than the specified 1000\n",
      "Created a chunk of size 1854, which is longer than the specified 1000\n",
      "Created a chunk of size 2304, which is longer than the specified 1000\n",
      "Created a chunk of size 1633, which is longer than the specified 1000\n",
      "Created a chunk of size 1618, which is longer than the specified 1000\n",
      "Created a chunk of size 2567, which is longer than the specified 1000\n",
      "Created a chunk of size 1076, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1592, which is longer than the specified 1000\n",
      "Created a chunk of size 1113, which is longer than the specified 1000\n",
      "Created a chunk of size 1065, which is longer than the specified 1000\n",
      "Created a chunk of size 1331, which is longer than the specified 1000\n",
      "Created a chunk of size 2399, which is longer than the specified 1000\n",
      "Created a chunk of size 1255, which is longer than the specified 1000\n",
      "Created a chunk of size 1318, which is longer than the specified 1000\n",
      "Created a chunk of size 2691, which is longer than the specified 1000\n",
      "Created a chunk of size 1079, which is longer than the specified 1000\n",
      "Created a chunk of size 1774, which is longer than the specified 1000\n",
      "Created a chunk of size 1350, which is longer than the specified 1000\n",
      "Created a chunk of size 2331, which is longer than the specified 1000\n",
      "Created a chunk of size 1306, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 2198, which is longer than the specified 1000\n",
      "Created a chunk of size 1851, which is longer than the specified 1000\n",
      "Created a chunk of size 1390, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1443, which is longer than the specified 1000\n",
      "Created a chunk of size 1558, which is longer than the specified 1000\n",
      "Created a chunk of size 1757, which is longer than the specified 1000\n",
      "Created a chunk of size 1395, which is longer than the specified 1000\n",
      "Created a chunk of size 2180, which is longer than the specified 1000\n",
      "Created a chunk of size 1178, which is longer than the specified 1000\n",
      "Created a chunk of size 1623, which is longer than the specified 1000\n",
      "Created a chunk of size 1491, which is longer than the specified 1000\n",
      "Created a chunk of size 2047, which is longer than the specified 1000\n",
      "Created a chunk of size 1782, which is longer than the specified 1000\n",
      "Created a chunk of size 2479, which is longer than the specified 1000\n",
      "Created a chunk of size 1127, which is longer than the specified 1000\n",
      "Created a chunk of size 1491, which is longer than the specified 1000\n",
      "Created a chunk of size 2384, which is longer than the specified 1000\n",
      "Created a chunk of size 1620, which is longer than the specified 1000\n",
      "Created a chunk of size 1530, which is longer than the specified 1000\n",
      "Created a chunk of size 2589, which is longer than the specified 1000\n",
      "Created a chunk of size 2147, which is longer than the specified 1000\n",
      "Created a chunk of size 2552, which is longer than the specified 1000\n",
      "Created a chunk of size 2739, which is longer than the specified 1000\n",
      "Created a chunk of size 1280, which is longer than the specified 1000\n",
      "Created a chunk of size 1305, which is longer than the specified 1000\n",
      "Created a chunk of size 1039, which is longer than the specified 1000\n",
      "Created a chunk of size 1035, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 2030, which is longer than the specified 1000\n",
      "Created a chunk of size 1438, which is longer than the specified 1000\n",
      "Created a chunk of size 1135, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1388, which is longer than the specified 1000\n",
      "Created a chunk of size 1401, which is longer than the specified 1000\n",
      "Created a chunk of size 1464, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1234, which is longer than the specified 1000\n",
      "Created a chunk of size 1949, which is longer than the specified 1000\n",
      "Created a chunk of size 1317, which is longer than the specified 1000\n",
      "Created a chunk of size 1138, which is longer than the specified 1000\n",
      "Created a chunk of size 1577, which is longer than the specified 1000\n",
      "Created a chunk of size 1286, which is longer than the specified 1000\n",
      "Created a chunk of size 1308, which is longer than the specified 1000\n",
      "Created a chunk of size 1278, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 2249, which is longer than the specified 1000\n",
      "Created a chunk of size 1925, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 1237, which is longer than the specified 1000\n",
      "Created a chunk of size 1380, which is longer than the specified 1000\n",
      "Created a chunk of size 1550, which is longer than the specified 1000\n",
      "Created a chunk of size 1811, which is longer than the specified 1000\n",
      "Created a chunk of size 1255, which is longer than the specified 1000\n",
      "Created a chunk of size 2011, which is longer than the specified 1000\n",
      "Created a chunk of size 1392, which is longer than the specified 1000\n",
      "Created a chunk of size 2077, which is longer than the specified 1000\n",
      "Created a chunk of size 2698, which is longer than the specified 1000\n",
      "Created a chunk of size 1826, which is longer than the specified 1000\n",
      "Created a chunk of size 2263, which is longer than the specified 1000\n",
      "Created a chunk of size 1024, which is longer than the specified 1000\n",
      "Created a chunk of size 1013, which is longer than the specified 1000\n",
      "Created a chunk of size 2167, which is longer than the specified 1000\n",
      "Created a chunk of size 1724, which is longer than the specified 1000\n",
      "Created a chunk of size 1240, which is longer than the specified 1000\n",
      "Created a chunk of size 1392, which is longer than the specified 1000\n",
      "Created a chunk of size 1366, which is longer than the specified 1000\n",
      "Created a chunk of size 1029, which is longer than the specified 1000\n",
      "Created a chunk of size 1105, which is longer than the specified 1000\n",
      "Created a chunk of size 1242, which is longer than the specified 1000\n",
      "Created a chunk of size 1189, which is longer than the specified 1000\n",
      "Created a chunk of size 1130, which is longer than the specified 1000\n",
      "Created a chunk of size 1324, which is longer than the specified 1000\n",
      "Created a chunk of size 1146, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 1329, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1859, which is longer than the specified 1000\n",
      "Created a chunk of size 1482, which is longer than the specified 1000\n",
      "Created a chunk of size 1351, which is longer than the specified 1000\n",
      "Created a chunk of size 1171, which is longer than the specified 1000\n",
      "Created a chunk of size 1327, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1127, which is longer than the specified 1000\n",
      "Created a chunk of size 1074, which is longer than the specified 1000\n",
      "Created a chunk of size 1646, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 2561, which is longer than the specified 1000\n",
      "Created a chunk of size 1226, which is longer than the specified 1000\n",
      "Created a chunk of size 1897, which is longer than the specified 1000\n",
      "Created a chunk of size 1203, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n",
      "Created a chunk of size 1512, which is longer than the specified 1000\n",
      "Created a chunk of size 1059, which is longer than the specified 1000\n",
      "Created a chunk of size 1202, which is longer than the specified 1000\n",
      "Created a chunk of size 1442, which is longer than the specified 1000\n",
      "Created a chunk of size 1601, which is longer than the specified 1000\n",
      "Created a chunk of size 2023, which is longer than the specified 1000\n",
      "Created a chunk of size 1729, which is longer than the specified 1000\n",
      "Created a chunk of size 2017, which is longer than the specified 1000\n",
      "Created a chunk of size 1798, which is longer than the specified 1000\n",
      "Created a chunk of size 2495, which is longer than the specified 1000\n",
      "Created a chunk of size 2379, which is longer than the specified 1000\n",
      "Created a chunk of size 2493, which is longer than the specified 1000\n",
      "Created a chunk of size 2147, which is longer than the specified 1000\n",
      "Created a chunk of size 1867, which is longer than the specified 1000\n",
      "Created a chunk of size 1840, which is longer than the specified 1000\n",
      "Created a chunk of size 2879, which is longer than the specified 1000\n",
      "Created a chunk of size 1190, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1873, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1523, which is longer than the specified 1000\n",
      "Created a chunk of size 1219, which is longer than the specified 1000\n",
      "Created a chunk of size 1715, which is longer than the specified 1000\n",
      "Created a chunk of size 2484, which is longer than the specified 1000\n",
      "Created a chunk of size 2362, which is longer than the specified 1000\n",
      "Created a chunk of size 2184, which is longer than the specified 1000\n",
      "Created a chunk of size 1288, which is longer than the specified 1000\n",
      "Created a chunk of size 1829, which is longer than the specified 1000\n",
      "Created a chunk of size 2540, which is longer than the specified 1000\n",
      "Created a chunk of size 1779, which is longer than the specified 1000\n",
      "Created a chunk of size 1306, which is longer than the specified 1000\n",
      "Created a chunk of size 1156, which is longer than the specified 1000\n",
      "Created a chunk of size 1329, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1743, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 2011, which is longer than the specified 1000\n",
      "Created a chunk of size 1497, which is longer than the specified 1000\n",
      "Created a chunk of size 2800, which is longer than the specified 1000\n",
      "Created a chunk of size 1952, which is longer than the specified 1000\n",
      "Created a chunk of size 2899, which is longer than the specified 1000\n",
      "Created a chunk of size 1850, which is longer than the specified 1000\n",
      "Created a chunk of size 1487, which is longer than the specified 1000\n",
      "Created a chunk of size 1368, which is longer than the specified 1000\n",
      "Created a chunk of size 1239, which is longer than the specified 1000\n",
      "Created a chunk of size 2946, which is longer than the specified 1000\n",
      "Created a chunk of size 2047, which is longer than the specified 1000\n",
      "Created a chunk of size 2924, which is longer than the specified 1000\n",
      "Created a chunk of size 1093, which is longer than the specified 1000\n",
      "Created a chunk of size 1007, which is longer than the specified 1000\n",
      "Created a chunk of size 1237, which is longer than the specified 1000\n",
      "Created a chunk of size 1893, which is longer than the specified 1000\n",
      "Created a chunk of size 1320, which is longer than the specified 1000\n",
      "Created a chunk of size 1655, which is longer than the specified 1000\n",
      "Created a chunk of size 1729, which is longer than the specified 1000\n",
      "Created a chunk of size 1794, which is longer than the specified 1000\n",
      "Created a chunk of size 1446, which is longer than the specified 1000\n",
      "Created a chunk of size 1148, which is longer than the specified 1000\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 1879, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 1396, which is longer than the specified 1000\n",
      "Created a chunk of size 1021, which is longer than the specified 1000\n",
      "Created a chunk of size 1087, which is longer than the specified 1000\n",
      "Created a chunk of size 1490, which is longer than the specified 1000\n",
      "Created a chunk of size 1916, which is longer than the specified 1000\n",
      "Created a chunk of size 1062, which is longer than the specified 1000\n",
      "Created a chunk of size 1033, which is longer than the specified 1000\n",
      "Created a chunk of size 1262, which is longer than the specified 1000\n",
      "Created a chunk of size 2013, which is longer than the specified 1000\n",
      "Created a chunk of size 1430, which is longer than the specified 1000\n",
      "Created a chunk of size 1756, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 1531, which is longer than the specified 1000\n",
      "Created a chunk of size 1608, which is longer than the specified 1000\n",
      "Created a chunk of size 2222, which is longer than the specified 1000\n",
      "Created a chunk of size 2512, which is longer than the specified 1000\n",
      "Created a chunk of size 1803, which is longer than the specified 1000\n",
      "Created a chunk of size 1166, which is longer than the specified 1000\n",
      "Created a chunk of size 1545, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1004, which is longer than the specified 1000\n",
      "Created a chunk of size 1202, which is longer than the specified 1000\n",
      "Created a chunk of size 1271, which is longer than the specified 1000\n",
      "Created a chunk of size 1918, which is longer than the specified 1000\n",
      "Created a chunk of size 1151, which is longer than the specified 1000\n",
      "Created a chunk of size 1122, which is longer than the specified 1000\n",
      "Created a chunk of size 1719, which is longer than the specified 1000\n",
      "Created a chunk of size 2124, which is longer than the specified 1000\n",
      "Created a chunk of size 1602, which is longer than the specified 1000\n",
      "Created a chunk of size 2990, which is longer than the specified 1000\n",
      "Created a chunk of size 2297, which is longer than the specified 1000\n",
      "Created a chunk of size 1734, which is longer than the specified 1000\n",
      "Created a chunk of size 2973, which is longer than the specified 1000\n",
      "Created a chunk of size 1925, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1252, which is longer than the specified 1000\n",
      "Created a chunk of size 1415, which is longer than the specified 1000\n",
      "Created a chunk of size 1386, which is longer than the specified 1000\n",
      "Created a chunk of size 2372, which is longer than the specified 1000\n",
      "Created a chunk of size 1655, which is longer than the specified 1000\n",
      "Created a chunk of size 1617, which is longer than the specified 1000\n",
      "Created a chunk of size 2109, which is longer than the specified 1000\n",
      "Created a chunk of size 2022, which is longer than the specified 1000\n",
      "Created a chunk of size 1745, which is longer than the specified 1000\n",
      "Created a chunk of size 1819, which is longer than the specified 1000\n",
      "Created a chunk of size 2194, which is longer than the specified 1000\n",
      "Created a chunk of size 2425, which is longer than the specified 1000\n",
      "Created a chunk of size 1968, which is longer than the specified 1000\n",
      "Created a chunk of size 1837, which is longer than the specified 1000\n",
      "Created a chunk of size 1609, which is longer than the specified 1000\n",
      "Created a chunk of size 2924, which is longer than the specified 1000\n",
      "Created a chunk of size 1244, which is longer than the specified 1000\n",
      "Created a chunk of size 2546, which is longer than the specified 1000\n",
      "Created a chunk of size 1261, which is longer than the specified 1000\n",
      "Created a chunk of size 1595, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1811, which is longer than the specified 1000\n",
      "Created a chunk of size 1957, which is longer than the specified 1000\n",
      "Created a chunk of size 2436, which is longer than the specified 1000\n",
      "Created a chunk of size 1616, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1164, which is longer than the specified 1000\n",
      "Created a chunk of size 1037, which is longer than the specified 1000\n",
      "Created a chunk of size 1669, which is longer than the specified 1000\n",
      "Created a chunk of size 1921, which is longer than the specified 1000\n",
      "Created a chunk of size 1401, which is longer than the specified 1000\n",
      "Created a chunk of size 1218, which is longer than the specified 1000\n",
      "Created a chunk of size 2324, which is longer than the specified 1000\n",
      "Created a chunk of size 1369, which is longer than the specified 1000\n",
      "Created a chunk of size 1109, which is longer than the specified 1000\n",
      "Created a chunk of size 1973, which is longer than the specified 1000\n",
      "Created a chunk of size 1123, which is longer than the specified 1000\n",
      "Created a chunk of size 1209, which is longer than the specified 1000\n",
      "Created a chunk of size 1811, which is longer than the specified 1000\n",
      "Created a chunk of size 2768, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1583, which is longer than the specified 1000\n",
      "Created a chunk of size 1442, which is longer than the specified 1000\n",
      "Created a chunk of size 2397, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 1345, which is longer than the specified 1000\n",
      "Created a chunk of size 1516, which is longer than the specified 1000\n",
      "Created a chunk of size 2390, which is longer than the specified 1000\n",
      "Created a chunk of size 1120, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1374, which is longer than the specified 1000\n",
      "Created a chunk of size 1273, which is longer than the specified 1000\n",
      "Created a chunk of size 2178, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 1555, which is longer than the specified 1000\n",
      "Created a chunk of size 2462, which is longer than the specified 1000\n",
      "Created a chunk of size 1211, which is longer than the specified 1000\n",
      "Created a chunk of size 1013, which is longer than the specified 1000\n",
      "Created a chunk of size 1333, which is longer than the specified 1000\n",
      "Created a chunk of size 1942, which is longer than the specified 1000\n",
      "Created a chunk of size 2295, which is longer than the specified 1000\n",
      "Created a chunk of size 2500, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 2868, which is longer than the specified 1000\n",
      "Created a chunk of size 1267, which is longer than the specified 1000\n",
      "Created a chunk of size 2179, which is longer than the specified 1000\n",
      "Created a chunk of size 1863, which is longer than the specified 1000\n",
      "Created a chunk of size 1387, which is longer than the specified 1000\n",
      "Created a chunk of size 1039, which is longer than the specified 1000\n",
      "Created a chunk of size 2259, which is longer than the specified 1000\n",
      "Created a chunk of size 2160, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 2292, which is longer than the specified 1000\n",
      "Created a chunk of size 1566, which is longer than the specified 1000\n",
      "Created a chunk of size 1095, which is longer than the specified 1000\n",
      "Created a chunk of size 1507, which is longer than the specified 1000\n",
      "Created a chunk of size 1592, which is longer than the specified 1000\n",
      "Created a chunk of size 1725, which is longer than the specified 1000\n",
      "Created a chunk of size 1096, which is longer than the specified 1000\n",
      "Created a chunk of size 1117, which is longer than the specified 1000\n",
      "Created a chunk of size 1247, which is longer than the specified 1000\n",
      "Created a chunk of size 1248, which is longer than the specified 1000\n",
      "Created a chunk of size 1028, which is longer than the specified 1000\n",
      "Created a chunk of size 1081, which is longer than the specified 1000\n",
      "Created a chunk of size 2234, which is longer than the specified 1000\n",
      "Created a chunk of size 1110, which is longer than the specified 1000\n",
      "Created a chunk of size 1947, which is longer than the specified 1000\n",
      "Created a chunk of size 1472, which is longer than the specified 1000\n",
      "Created a chunk of size 1038, which is longer than the specified 1000\n",
      "Created a chunk of size 1294, which is longer than the specified 1000\n",
      "Created a chunk of size 1490, which is longer than the specified 1000\n",
      "Created a chunk of size 1476, which is longer than the specified 1000\n",
      "Created a chunk of size 1494, which is longer than the specified 1000\n",
      "Created a chunk of size 1180, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1050, which is longer than the specified 1000\n",
      "Created a chunk of size 1363, which is longer than the specified 1000\n",
      "Created a chunk of size 1172, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1217, which is longer than the specified 1000\n",
      "Created a chunk of size 1199, which is longer than the specified 1000\n",
      "Created a chunk of size 1398, which is longer than the specified 1000\n",
      "Created a chunk of size 1312, which is longer than the specified 1000\n",
      "Created a chunk of size 1193, which is longer than the specified 1000\n",
      "Created a chunk of size 1147, which is longer than the specified 1000\n",
      "Created a chunk of size 1153, which is longer than the specified 1000\n",
      "Created a chunk of size 1858, which is longer than the specified 1000\n",
      "Created a chunk of size 1339, which is longer than the specified 1000\n",
      "Created a chunk of size 1169, which is longer than the specified 1000\n",
      "Created a chunk of size 1292, which is longer than the specified 1000\n",
      "Created a chunk of size 1341, which is longer than the specified 1000\n",
      "Created a chunk of size 1628, which is longer than the specified 1000\n",
      "Created a chunk of size 1185, which is longer than the specified 1000\n",
      "Created a chunk of size 2473, which is longer than the specified 1000\n",
      "Created a chunk of size 1038, which is longer than the specified 1000\n",
      "Created a chunk of size 1478, which is longer than the specified 1000\n",
      "Created a chunk of size 1122, which is longer than the specified 1000\n",
      "Created a chunk of size 1033, which is longer than the specified 1000\n",
      "Created a chunk of size 1373, which is longer than the specified 1000\n",
      "Created a chunk of size 1095, which is longer than the specified 1000\n",
      "Created a chunk of size 1386, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1243, which is longer than the specified 1000\n",
      "Created a chunk of size 1062, which is longer than the specified 1000\n",
      "Created a chunk of size 1632, which is longer than the specified 1000\n",
      "Created a chunk of size 1846, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 2989, which is longer than the specified 1000\n",
      "Created a chunk of size 1093, which is longer than the specified 1000\n",
      "Created a chunk of size 1794, which is longer than the specified 1000\n",
      "Created a chunk of size 1637, which is longer than the specified 1000\n",
      "Created a chunk of size 1571, which is longer than the specified 1000\n",
      "Created a chunk of size 1495, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 2738, which is longer than the specified 1000\n",
      "Created a chunk of size 1065, which is longer than the specified 1000\n",
      "Created a chunk of size 1346, which is longer than the specified 1000\n",
      "Created a chunk of size 1013, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Document Chunks Information----\n",
      "Number of document chunks: 1278\n",
      "\n",
      "-----Create embeddings------\n",
      "\n",
      "--- Finished creating embeddings----\n"
     ]
    }
   ],
   "source": [
    "# Check if chroma vector store already exists\n",
    "if not os.path.exists(persistent_directory):\n",
    "    print(\"persistent directory does not exist. Initializing vector store...\")\n",
    "\n",
    "    # Ensure the books directory exists\n",
    "    if not os.path.exists(books_dir):\n",
    "        raise FileNotFoundError(\n",
    "            f\"The directory {book_dir} does not exists. Please check the path\"\n",
    "        )\n",
    "    \n",
    "    # List all text files in directory (earlier it was just one book)\n",
    "    book_files = [f for f in os.listdir(books_dir) if f.endswith(\".txt\")]\n",
    "\n",
    "    # Read the text content for each file and store it with metadata\n",
    "    # Chunking multiple files and storing them here ergo the for loop\n",
    "    documents = []\n",
    "    for book_file in book_files:\n",
    "        file_path = os.path.join(books_dir, book_file)\n",
    "        loader = TextLoader(file_path)\n",
    "        book_docs = loader.load()\n",
    "        for doc in book_docs:\n",
    "            # Add metadata to each document indicating its source\n",
    "            doc.metadata = {\"source\": book_file}\n",
    "            documents.append(doc)\n",
    "\n",
    "    # Split the document into chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # display information about the split documents\n",
    "    print(\"\\n---- Document Chunks Information----\")\n",
    "    print(f\"Number of document chunks: {len(docs)}\")\n",
    "\n",
    "    # Create embeddings\n",
    "    print(\"\\n-----Create embeddings------\")\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "    print(\"\\n--- Finished creating embeddings----\")\n",
    "\n",
    "    # Create the vector store and persist it\n",
    "    db = Chroma.from_documents(\n",
    "        docs, embedding=embeddings, persist_directory=persistent_directory\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"vector store already exists. No need to initialize\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b RAG Basics with Metadata and Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the persistent directory\n",
    "current_dir = os.path.abspath(\"\")\n",
    "db_dir = os.path.join(current_dir, \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embeddings\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's question\n",
    "query = \"What is unique market insight?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the relevant documents based on query\n",
    "retriever = db.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs={\"k\":3},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents ---\n",
      "Document 1:\n",
      "Consider the Point of View of\n",
      "Your Best-Fit Customers\n",
      "One way of thinking about your unique market insight is to ask this\n",
      "question: “What do your best-fit prospects need to know to understand why\n",
      "your unique value is important to them?”\n",
      "\n",
      "Your unique insight\n",
      "into the market is what\n",
      "leads you to build a\n",
      "product that is different\n",
      "and better than the\n",
      "alternatives.\n",
      "\n",
      "Source: Sales_Pitch_April_Dunford.txt\n",
      "\n",
      "Document 2:\n",
      "Insight That Isn’t Unique\n",
      "Some companies will try to use a common industry trend as insight at the\n",
      "start of their sales pitch, rather than the company’s unique insight into the\n",
      "market. For example, I have seen variations of “Companies are generating\n",
      "more data than ever before,” or “The pace of AI adoption is accelerating,”\n",
      "or “Companies need to digitally transform their businesses.” All of these are\n",
      "obvious trends in the market. The key to Step 1, Insight, is to go beyond\n",
      "these surface-level observations and get down to the insight that makes your\n",
      "solution uniquely valuable. Your insight should be unique and differentiated\n",
      "because you need it to set up the reasoning behind why your unique,\n",
      "differentiated value is important.\n",
      "\n",
      "Source: Sales_Pitch_April_Dunford.txt\n",
      "\n",
      "Document 3:\n",
      "How Do You Determine Your Insight?\n",
      "I believe that every successful company has a unique point of view on the\n",
      "market—they just aren’t always great at articulating it. Sometimes you\n",
      "know exactly what your unique insight is because your product was\n",
      "originally designed around it. Other companies develop their insight as they\n",
      "sell more product and gradually gain a better understanding of their\n",
      "customers, their situation, and the value they can bring to the table that\n",
      "other alternative solutions cannot.\n",
      "\n",
      "In both cases, there may be individual folks on the team who can speak to\n",
      "the company’s point of view, but often, sales and marketing teams fall into\n",
      "the trap of focusing on “the problem” or market trends because they’re\n",
      "more obvious and therefore easier to identify. The words for these problems\n",
      "and trends already exist in the market, making it easy to write and talk\n",
      "about them.\n",
      "\n",
      "Source: Sales_Pitch_April_Dunford.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the relevant results with metadata\n",
    "print(\"\\n--- Relevant Documents ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "    print(f\"Source: {doc.metadata['source']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Splitting Deep-Dive\n",
    "\n",
    "(Recursvie text splitter seems to be the best)\n",
    "\n",
    "LangChain provides several types of text splitters, each designed for specific use cases. Here's a breakdown of the most common ones:\n",
    "\n",
    "1. **CharacterTextSplitter**:\n",
    "   - Splits text based on a fixed number of characters.\n",
    "   - Useful for simple and consistent chunking.\n",
    "   - Example: Splitting a document into chunks of 1,000 characters each.\n",
    "\n",
    "2. **RecursiveCharacterTextSplitter**:\n",
    "   - Splits text recursively by attempting to break it at natural boundaries (e.g., paragraphs, sentences) while respecting a maximum chunk size.\n",
    "   - Ideal for preserving semantic meaning and context within chunks.\n",
    "   - Recommended for most use cases due to its balance of structure and flexibility.\n",
    "\n",
    "3. **TokenTextSplitter**:\n",
    "   - Splits text based on the number of tokens, which are units of text used by language models.\n",
    "   - Ensures that chunks fit within the token limit of a model.\n",
    "   - Useful when working with models that have strict token constraints.\n",
    "\n",
    "4. **MarkdownTextSplitter**:\n",
    "   - Specifically designed for splitting Markdown documents.\n",
    "   - Preserves the structure of Markdown content, such as headings and lists.\n",
    "   - Ideal for processing technical documentation or structured text.\n",
    "\n",
    "5. **HTMLTextSplitter**:\n",
    "   - Splits HTML content while maintaining its structure.\n",
    "   - Useful for web scraping or processing HTML documents.\n",
    "\n",
    "6. **SemanticTextSplitter**:\n",
    "   - Uses embeddings and similarity measures to split text at semantically meaningful points.\n",
    "   - Ensures that related content stays together.\n",
    "   - Best for applications requiring high semantic relevance.\n",
    "\n",
    "Each splitter has its strengths, and the choice depends on your specific requirements, such as the type of text, the model's input constraints, and the importance of preserving semantic meaning. Would you like help implementing any of these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    SentenceTransformersTokenTextSplitter,\n",
    "    TextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Load the Text File**\n",
    "- Use the `TextLoader` class to read the file from `file_path`.\n",
    "- Extract the file content into `documents`, which will later be split into smaller chunks.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Select the Embedding Model**\n",
    "- Initialize an `OpenAIEmbeddings` model that will later be used to convert text into numerical embeddings. \n",
    "- At this step, the model is simply being set up—it does not yet process the text.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Define the Vector Store Function**\n",
    "- Create a function, `create_vector_store`, that:\n",
    "  1. Takes in the processed document chunks.\n",
    "  2. Generates embeddings using the selected model.\n",
    "  3. Saves these embeddings to a persistent database (a vector store) using the `Chroma` library.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Split Text into Chunks and Store Them**\n",
    "\n",
    "To prepare the text for embedding, it’s split into smaller, manageable pieces using different techniques. Each technique creates a new set of chunks, which are then saved in their respective vector stores:\n",
    "\n",
    "1. **Character-based Splitting**\n",
    "   - Divide text into chunks of 1,000 characters with 100-character overlaps.\n",
    "   - Save the chunks in a database called `\"chroma_db_char\"`.\n",
    "\n",
    "2. **Sentence-based Splitting**\n",
    "   - Break text into chunks at sentence boundaries, ensuring complete sentences in each chunk.\n",
    "   - Store these chunks in `\"chroma_db_sent\"`.\n",
    "\n",
    "3. **Token-based Splitting**\n",
    "   - Divide the text into chunks of 512 tokens (e.g., words or subwords) to match transformer models' input limits.\n",
    "   - Save the chunks in `\"chroma_db_token\"`.\n",
    "\n",
    "4. **Recursive Character-based Splitting**\n",
    "   - Attempt to split text at natural boundaries (e.g., sentences, paragraphs) while keeping chunks under 1,000 characters.\n",
    "   - Save the resulting chunks in `\"chroma_db_rec_char\"`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Workflow Summary**\n",
    "1. **Load the text**: Read the file into memory.\n",
    "2. **Pick the embedding model**: Set up the embeddings tool.\n",
    "3. **Process the text**: Split it into smaller chunks using various methods.\n",
    "4. **Store the embeddings**: Create and save a vector store for each splitting technique.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the text file\n",
    "current_dir = os.path.abspath(\"\")\n",
    "file_path = os.path.join(current_dir, \"books\", \"AI_Engineering.txt\")\n",
    "db_dir = os.path.join(current_dir, \"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the text file exists\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"The file {file_path} does not exist. Please check the path.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text content from the file\n",
    "loader = TextLoader(file_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and persist vector store\n",
    "\n",
    "def create_vector_store(docs, store_name):\n",
    "    persistent_directory = os.path.join(db_dir, store_name)\n",
    "    if not os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--- Creating vector store {store_name} ---\")\n",
    "        db = Chroma.from_documents(\n",
    "            docs, embeddings, persist_directory=persistent_directory\n",
    "        )\n",
    "        print(f\"--- Finished creating vector store {store_name} ---\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Vector store {store_name} already exists. No need to initialize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1384, which is longer than the specified 1000\n",
      "Created a chunk of size 1145, which is longer than the specified 1000\n",
      "Created a chunk of size 1024, which is longer than the specified 1000\n",
      "Created a chunk of size 1686, which is longer than the specified 1000\n",
      "Created a chunk of size 1771, which is longer than the specified 1000\n",
      "Created a chunk of size 1054, which is longer than the specified 1000\n",
      "Created a chunk of size 1109, which is longer than the specified 1000\n",
      "Created a chunk of size 1151, which is longer than the specified 1000\n",
      "Created a chunk of size 1458, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n",
      "Created a chunk of size 2743, which is longer than the specified 1000\n",
      "Created a chunk of size 2103, which is longer than the specified 1000\n",
      "Created a chunk of size 2328, which is longer than the specified 1000\n",
      "Created a chunk of size 2424, which is longer than the specified 1000\n",
      "Created a chunk of size 1636, which is longer than the specified 1000\n",
      "Created a chunk of size 1263, which is longer than the specified 1000\n",
      "Created a chunk of size 1370, which is longer than the specified 1000\n",
      "Created a chunk of size 1494, which is longer than the specified 1000\n",
      "Created a chunk of size 1456, which is longer than the specified 1000\n",
      "Created a chunk of size 1627, which is longer than the specified 1000\n",
      "Created a chunk of size 1677, which is longer than the specified 1000\n",
      "Created a chunk of size 1684, which is longer than the specified 1000\n",
      "Created a chunk of size 1761, which is longer than the specified 1000\n",
      "Created a chunk of size 2491, which is longer than the specified 1000\n",
      "Created a chunk of size 1046, which is longer than the specified 1000\n",
      "Created a chunk of size 1500, which is longer than the specified 1000\n",
      "Created a chunk of size 1358, which is longer than the specified 1000\n",
      "Created a chunk of size 1377, which is longer than the specified 1000\n",
      "Created a chunk of size 1215, which is longer than the specified 1000\n",
      "Created a chunk of size 1741, which is longer than the specified 1000\n",
      "Created a chunk of size 2474, which is longer than the specified 1000\n",
      "Created a chunk of size 1279, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1839, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 1464, which is longer than the specified 1000\n",
      "Created a chunk of size 2155, which is longer than the specified 1000\n",
      "Created a chunk of size 2123, which is longer than the specified 1000\n",
      "Created a chunk of size 1326, which is longer than the specified 1000\n",
      "Created a chunk of size 1574, which is longer than the specified 1000\n",
      "Created a chunk of size 1103, which is longer than the specified 1000\n",
      "Created a chunk of size 1593, which is longer than the specified 1000\n",
      "Created a chunk of size 2252, which is longer than the specified 1000\n",
      "Created a chunk of size 1077, which is longer than the specified 1000\n",
      "Created a chunk of size 1658, which is longer than the specified 1000\n",
      "Created a chunk of size 1135, which is longer than the specified 1000\n",
      "Created a chunk of size 2176, which is longer than the specified 1000\n",
      "Created a chunk of size 1207, which is longer than the specified 1000\n",
      "Created a chunk of size 1690, which is longer than the specified 1000\n",
      "Created a chunk of size 1359, which is longer than the specified 1000\n",
      "Created a chunk of size 1311, which is longer than the specified 1000\n",
      "Created a chunk of size 1404, which is longer than the specified 1000\n",
      "Created a chunk of size 1100, which is longer than the specified 1000\n",
      "Created a chunk of size 1696, which is longer than the specified 1000\n",
      "Created a chunk of size 1890, which is longer than the specified 1000\n",
      "Created a chunk of size 1441, which is longer than the specified 1000\n",
      "Created a chunk of size 1458, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Character-based Splitting ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2038, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1856, which is longer than the specified 1000\n",
      "Created a chunk of size 1475, which is longer than the specified 1000\n",
      "Created a chunk of size 1394, which is longer than the specified 1000\n",
      "Created a chunk of size 1160, which is longer than the specified 1000\n",
      "Created a chunk of size 1837, which is longer than the specified 1000\n",
      "Created a chunk of size 1779, which is longer than the specified 1000\n",
      "Created a chunk of size 2066, which is longer than the specified 1000\n",
      "Created a chunk of size 2130, which is longer than the specified 1000\n",
      "Created a chunk of size 2013, which is longer than the specified 1000\n",
      "Created a chunk of size 1274, which is longer than the specified 1000\n",
      "Created a chunk of size 1259, which is longer than the specified 1000\n",
      "Created a chunk of size 2200, which is longer than the specified 1000\n",
      "Created a chunk of size 1939, which is longer than the specified 1000\n",
      "Created a chunk of size 1305, which is longer than the specified 1000\n",
      "Created a chunk of size 2099, which is longer than the specified 1000\n",
      "Created a chunk of size 2171, which is longer than the specified 1000\n",
      "Created a chunk of size 1040, which is longer than the specified 1000\n",
      "Created a chunk of size 1549, which is longer than the specified 1000\n",
      "Created a chunk of size 1126, which is longer than the specified 1000\n",
      "Created a chunk of size 1608, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1413, which is longer than the specified 1000\n",
      "Created a chunk of size 1727, which is longer than the specified 1000\n",
      "Created a chunk of size 1167, which is longer than the specified 1000\n",
      "Created a chunk of size 1892, which is longer than the specified 1000\n",
      "Created a chunk of size 1649, which is longer than the specified 1000\n",
      "Created a chunk of size 1574, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 2202, which is longer than the specified 1000\n",
      "Created a chunk of size 1245, which is longer than the specified 1000\n",
      "Created a chunk of size 1809, which is longer than the specified 1000\n",
      "Created a chunk of size 1212, which is longer than the specified 1000\n",
      "Created a chunk of size 1854, which is longer than the specified 1000\n",
      "Created a chunk of size 2304, which is longer than the specified 1000\n",
      "Created a chunk of size 1633, which is longer than the specified 1000\n",
      "Created a chunk of size 1618, which is longer than the specified 1000\n",
      "Created a chunk of size 2567, which is longer than the specified 1000\n",
      "Created a chunk of size 1076, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1592, which is longer than the specified 1000\n",
      "Created a chunk of size 1113, which is longer than the specified 1000\n",
      "Created a chunk of size 1065, which is longer than the specified 1000\n",
      "Created a chunk of size 1331, which is longer than the specified 1000\n",
      "Created a chunk of size 2399, which is longer than the specified 1000\n",
      "Created a chunk of size 1255, which is longer than the specified 1000\n",
      "Created a chunk of size 1318, which is longer than the specified 1000\n",
      "Created a chunk of size 2691, which is longer than the specified 1000\n",
      "Created a chunk of size 1079, which is longer than the specified 1000\n",
      "Created a chunk of size 1774, which is longer than the specified 1000\n",
      "Created a chunk of size 1350, which is longer than the specified 1000\n",
      "Created a chunk of size 2331, which is longer than the specified 1000\n",
      "Created a chunk of size 1306, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 2198, which is longer than the specified 1000\n",
      "Created a chunk of size 1851, which is longer than the specified 1000\n",
      "Created a chunk of size 1390, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1443, which is longer than the specified 1000\n",
      "Created a chunk of size 1558, which is longer than the specified 1000\n",
      "Created a chunk of size 1757, which is longer than the specified 1000\n",
      "Created a chunk of size 1395, which is longer than the specified 1000\n",
      "Created a chunk of size 2180, which is longer than the specified 1000\n",
      "Created a chunk of size 1178, which is longer than the specified 1000\n",
      "Created a chunk of size 1623, which is longer than the specified 1000\n",
      "Created a chunk of size 1491, which is longer than the specified 1000\n",
      "Created a chunk of size 2047, which is longer than the specified 1000\n",
      "Created a chunk of size 1782, which is longer than the specified 1000\n",
      "Created a chunk of size 2479, which is longer than the specified 1000\n",
      "Created a chunk of size 1127, which is longer than the specified 1000\n",
      "Created a chunk of size 1491, which is longer than the specified 1000\n",
      "Created a chunk of size 2384, which is longer than the specified 1000\n",
      "Created a chunk of size 1620, which is longer than the specified 1000\n",
      "Created a chunk of size 1530, which is longer than the specified 1000\n",
      "Created a chunk of size 2589, which is longer than the specified 1000\n",
      "Created a chunk of size 2147, which is longer than the specified 1000\n",
      "Created a chunk of size 2552, which is longer than the specified 1000\n",
      "Created a chunk of size 2739, which is longer than the specified 1000\n",
      "Created a chunk of size 1280, which is longer than the specified 1000\n",
      "Created a chunk of size 1305, which is longer than the specified 1000\n",
      "Created a chunk of size 1039, which is longer than the specified 1000\n",
      "Created a chunk of size 1035, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 2030, which is longer than the specified 1000\n",
      "Created a chunk of size 1438, which is longer than the specified 1000\n",
      "Created a chunk of size 1135, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1388, which is longer than the specified 1000\n",
      "Created a chunk of size 1401, which is longer than the specified 1000\n",
      "Created a chunk of size 1464, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1234, which is longer than the specified 1000\n",
      "Created a chunk of size 1949, which is longer than the specified 1000\n",
      "Created a chunk of size 1317, which is longer than the specified 1000\n",
      "Created a chunk of size 1138, which is longer than the specified 1000\n",
      "Created a chunk of size 1577, which is longer than the specified 1000\n",
      "Created a chunk of size 1286, which is longer than the specified 1000\n",
      "Created a chunk of size 1308, which is longer than the specified 1000\n",
      "Created a chunk of size 1278, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 2249, which is longer than the specified 1000\n",
      "Created a chunk of size 1925, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 1237, which is longer than the specified 1000\n",
      "Created a chunk of size 1380, which is longer than the specified 1000\n",
      "Created a chunk of size 1550, which is longer than the specified 1000\n",
      "Created a chunk of size 1811, which is longer than the specified 1000\n",
      "Created a chunk of size 1255, which is longer than the specified 1000\n",
      "Created a chunk of size 2011, which is longer than the specified 1000\n",
      "Created a chunk of size 1392, which is longer than the specified 1000\n",
      "Created a chunk of size 2077, which is longer than the specified 1000\n",
      "Created a chunk of size 2698, which is longer than the specified 1000\n",
      "Created a chunk of size 1826, which is longer than the specified 1000\n",
      "Created a chunk of size 2263, which is longer than the specified 1000\n",
      "Created a chunk of size 1024, which is longer than the specified 1000\n",
      "Created a chunk of size 1013, which is longer than the specified 1000\n",
      "Created a chunk of size 2167, which is longer than the specified 1000\n",
      "Created a chunk of size 1724, which is longer than the specified 1000\n",
      "Created a chunk of size 1240, which is longer than the specified 1000\n",
      "Created a chunk of size 1392, which is longer than the specified 1000\n",
      "Created a chunk of size 1366, which is longer than the specified 1000\n",
      "Created a chunk of size 1029, which is longer than the specified 1000\n",
      "Created a chunk of size 1105, which is longer than the specified 1000\n",
      "Created a chunk of size 1242, which is longer than the specified 1000\n",
      "Created a chunk of size 1189, which is longer than the specified 1000\n",
      "Created a chunk of size 1130, which is longer than the specified 1000\n",
      "Created a chunk of size 1324, which is longer than the specified 1000\n",
      "Created a chunk of size 1146, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 1329, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1859, which is longer than the specified 1000\n",
      "Created a chunk of size 1482, which is longer than the specified 1000\n",
      "Created a chunk of size 1351, which is longer than the specified 1000\n",
      "Created a chunk of size 1171, which is longer than the specified 1000\n",
      "Created a chunk of size 1327, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1127, which is longer than the specified 1000\n",
      "Created a chunk of size 1074, which is longer than the specified 1000\n",
      "Created a chunk of size 1646, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 2561, which is longer than the specified 1000\n",
      "Created a chunk of size 1226, which is longer than the specified 1000\n",
      "Created a chunk of size 1897, which is longer than the specified 1000\n",
      "Created a chunk of size 1203, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n",
      "Created a chunk of size 1512, which is longer than the specified 1000\n",
      "Created a chunk of size 1059, which is longer than the specified 1000\n",
      "Created a chunk of size 1202, which is longer than the specified 1000\n",
      "Created a chunk of size 1442, which is longer than the specified 1000\n",
      "Created a chunk of size 1601, which is longer than the specified 1000\n",
      "Created a chunk of size 2023, which is longer than the specified 1000\n",
      "Created a chunk of size 1729, which is longer than the specified 1000\n",
      "Created a chunk of size 2017, which is longer than the specified 1000\n",
      "Created a chunk of size 1798, which is longer than the specified 1000\n",
      "Created a chunk of size 2495, which is longer than the specified 1000\n",
      "Created a chunk of size 2379, which is longer than the specified 1000\n",
      "Created a chunk of size 2493, which is longer than the specified 1000\n",
      "Created a chunk of size 2147, which is longer than the specified 1000\n",
      "Created a chunk of size 1867, which is longer than the specified 1000\n",
      "Created a chunk of size 1840, which is longer than the specified 1000\n",
      "Created a chunk of size 2879, which is longer than the specified 1000\n",
      "Created a chunk of size 1190, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1873, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1523, which is longer than the specified 1000\n",
      "Created a chunk of size 1219, which is longer than the specified 1000\n",
      "Created a chunk of size 1715, which is longer than the specified 1000\n",
      "Created a chunk of size 2484, which is longer than the specified 1000\n",
      "Created a chunk of size 2362, which is longer than the specified 1000\n",
      "Created a chunk of size 2184, which is longer than the specified 1000\n",
      "Created a chunk of size 1288, which is longer than the specified 1000\n",
      "Created a chunk of size 1829, which is longer than the specified 1000\n",
      "Created a chunk of size 2540, which is longer than the specified 1000\n",
      "Created a chunk of size 1779, which is longer than the specified 1000\n",
      "Created a chunk of size 1306, which is longer than the specified 1000\n",
      "Created a chunk of size 1156, which is longer than the specified 1000\n",
      "Created a chunk of size 1329, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1743, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 2011, which is longer than the specified 1000\n",
      "Created a chunk of size 1497, which is longer than the specified 1000\n",
      "Created a chunk of size 2800, which is longer than the specified 1000\n",
      "Created a chunk of size 1952, which is longer than the specified 1000\n",
      "Created a chunk of size 2899, which is longer than the specified 1000\n",
      "Created a chunk of size 1850, which is longer than the specified 1000\n",
      "Created a chunk of size 1487, which is longer than the specified 1000\n",
      "Created a chunk of size 1368, which is longer than the specified 1000\n",
      "Created a chunk of size 1239, which is longer than the specified 1000\n",
      "Created a chunk of size 2946, which is longer than the specified 1000\n",
      "Created a chunk of size 2047, which is longer than the specified 1000\n",
      "Created a chunk of size 2924, which is longer than the specified 1000\n",
      "Created a chunk of size 1093, which is longer than the specified 1000\n",
      "Created a chunk of size 1007, which is longer than the specified 1000\n",
      "Created a chunk of size 1237, which is longer than the specified 1000\n",
      "Created a chunk of size 1893, which is longer than the specified 1000\n",
      "Created a chunk of size 1320, which is longer than the specified 1000\n",
      "Created a chunk of size 1655, which is longer than the specified 1000\n",
      "Created a chunk of size 1729, which is longer than the specified 1000\n",
      "Created a chunk of size 1794, which is longer than the specified 1000\n",
      "Created a chunk of size 1446, which is longer than the specified 1000\n",
      "Created a chunk of size 1148, which is longer than the specified 1000\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 1879, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 1396, which is longer than the specified 1000\n",
      "Created a chunk of size 1021, which is longer than the specified 1000\n",
      "Created a chunk of size 1087, which is longer than the specified 1000\n",
      "Created a chunk of size 1490, which is longer than the specified 1000\n",
      "Created a chunk of size 1916, which is longer than the specified 1000\n",
      "Created a chunk of size 1062, which is longer than the specified 1000\n",
      "Created a chunk of size 1033, which is longer than the specified 1000\n",
      "Created a chunk of size 1262, which is longer than the specified 1000\n",
      "Created a chunk of size 2013, which is longer than the specified 1000\n",
      "Created a chunk of size 1430, which is longer than the specified 1000\n",
      "Created a chunk of size 1756, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 1531, which is longer than the specified 1000\n",
      "Created a chunk of size 1608, which is longer than the specified 1000\n",
      "Created a chunk of size 2222, which is longer than the specified 1000\n",
      "Created a chunk of size 2512, which is longer than the specified 1000\n",
      "Created a chunk of size 1803, which is longer than the specified 1000\n",
      "Created a chunk of size 1166, which is longer than the specified 1000\n",
      "Created a chunk of size 1545, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1004, which is longer than the specified 1000\n",
      "Created a chunk of size 1202, which is longer than the specified 1000\n",
      "Created a chunk of size 1271, which is longer than the specified 1000\n",
      "Created a chunk of size 1918, which is longer than the specified 1000\n",
      "Created a chunk of size 1151, which is longer than the specified 1000\n",
      "Created a chunk of size 1122, which is longer than the specified 1000\n",
      "Created a chunk of size 1719, which is longer than the specified 1000\n",
      "Created a chunk of size 2124, which is longer than the specified 1000\n",
      "Created a chunk of size 1602, which is longer than the specified 1000\n",
      "Created a chunk of size 2990, which is longer than the specified 1000\n",
      "Created a chunk of size 2297, which is longer than the specified 1000\n",
      "Created a chunk of size 1734, which is longer than the specified 1000\n",
      "Created a chunk of size 2973, which is longer than the specified 1000\n",
      "Created a chunk of size 1925, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1252, which is longer than the specified 1000\n",
      "Created a chunk of size 1415, which is longer than the specified 1000\n",
      "Created a chunk of size 1386, which is longer than the specified 1000\n",
      "Created a chunk of size 2372, which is longer than the specified 1000\n",
      "Created a chunk of size 1655, which is longer than the specified 1000\n",
      "Created a chunk of size 1617, which is longer than the specified 1000\n",
      "Created a chunk of size 2109, which is longer than the specified 1000\n",
      "Created a chunk of size 2022, which is longer than the specified 1000\n",
      "Created a chunk of size 1745, which is longer than the specified 1000\n",
      "Created a chunk of size 1819, which is longer than the specified 1000\n",
      "Created a chunk of size 2194, which is longer than the specified 1000\n",
      "Created a chunk of size 2425, which is longer than the specified 1000\n",
      "Created a chunk of size 1968, which is longer than the specified 1000\n",
      "Created a chunk of size 1837, which is longer than the specified 1000\n",
      "Created a chunk of size 1609, which is longer than the specified 1000\n",
      "Created a chunk of size 2924, which is longer than the specified 1000\n",
      "Created a chunk of size 1244, which is longer than the specified 1000\n",
      "Created a chunk of size 2546, which is longer than the specified 1000\n",
      "Created a chunk of size 1261, which is longer than the specified 1000\n",
      "Created a chunk of size 1595, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1811, which is longer than the specified 1000\n",
      "Created a chunk of size 1957, which is longer than the specified 1000\n",
      "Created a chunk of size 2436, which is longer than the specified 1000\n",
      "Created a chunk of size 1616, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1164, which is longer than the specified 1000\n",
      "Created a chunk of size 1037, which is longer than the specified 1000\n",
      "Created a chunk of size 1669, which is longer than the specified 1000\n",
      "Created a chunk of size 1921, which is longer than the specified 1000\n",
      "Created a chunk of size 1401, which is longer than the specified 1000\n",
      "Created a chunk of size 1218, which is longer than the specified 1000\n",
      "Created a chunk of size 2324, which is longer than the specified 1000\n",
      "Created a chunk of size 1369, which is longer than the specified 1000\n",
      "Created a chunk of size 1109, which is longer than the specified 1000\n",
      "Created a chunk of size 1973, which is longer than the specified 1000\n",
      "Created a chunk of size 1123, which is longer than the specified 1000\n",
      "Created a chunk of size 1209, which is longer than the specified 1000\n",
      "Created a chunk of size 1811, which is longer than the specified 1000\n",
      "Created a chunk of size 2768, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1583, which is longer than the specified 1000\n",
      "Created a chunk of size 1442, which is longer than the specified 1000\n",
      "Created a chunk of size 2397, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 1345, which is longer than the specified 1000\n",
      "Created a chunk of size 1516, which is longer than the specified 1000\n",
      "Created a chunk of size 2390, which is longer than the specified 1000\n",
      "Created a chunk of size 1120, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1374, which is longer than the specified 1000\n",
      "Created a chunk of size 1273, which is longer than the specified 1000\n",
      "Created a chunk of size 2178, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 1555, which is longer than the specified 1000\n",
      "Created a chunk of size 2462, which is longer than the specified 1000\n",
      "Created a chunk of size 1211, which is longer than the specified 1000\n",
      "Created a chunk of size 1013, which is longer than the specified 1000\n",
      "Created a chunk of size 1333, which is longer than the specified 1000\n",
      "Created a chunk of size 1942, which is longer than the specified 1000\n",
      "Created a chunk of size 2295, which is longer than the specified 1000\n",
      "Created a chunk of size 2500, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 2868, which is longer than the specified 1000\n",
      "Created a chunk of size 1267, which is longer than the specified 1000\n",
      "Created a chunk of size 2179, which is longer than the specified 1000\n",
      "Created a chunk of size 1863, which is longer than the specified 1000\n",
      "Created a chunk of size 1387, which is longer than the specified 1000\n",
      "Created a chunk of size 1039, which is longer than the specified 1000\n",
      "Created a chunk of size 2259, which is longer than the specified 1000\n",
      "Created a chunk of size 2160, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 2292, which is longer than the specified 1000\n",
      "Created a chunk of size 1566, which is longer than the specified 1000\n",
      "Created a chunk of size 1095, which is longer than the specified 1000\n",
      "Created a chunk of size 1507, which is longer than the specified 1000\n",
      "Created a chunk of size 1592, which is longer than the specified 1000\n",
      "Created a chunk of size 1725, which is longer than the specified 1000\n",
      "Created a chunk of size 1096, which is longer than the specified 1000\n",
      "Created a chunk of size 1117, which is longer than the specified 1000\n",
      "Created a chunk of size 1247, which is longer than the specified 1000\n",
      "Created a chunk of size 1248, which is longer than the specified 1000\n",
      "Created a chunk of size 1028, which is longer than the specified 1000\n",
      "Created a chunk of size 1081, which is longer than the specified 1000\n",
      "Created a chunk of size 2234, which is longer than the specified 1000\n",
      "Created a chunk of size 1110, which is longer than the specified 1000\n",
      "Created a chunk of size 1947, which is longer than the specified 1000\n",
      "Created a chunk of size 1472, which is longer than the specified 1000\n",
      "Created a chunk of size 1038, which is longer than the specified 1000\n",
      "Created a chunk of size 1294, which is longer than the specified 1000\n",
      "Created a chunk of size 1490, which is longer than the specified 1000\n",
      "Created a chunk of size 1476, which is longer than the specified 1000\n",
      "Created a chunk of size 1494, which is longer than the specified 1000\n",
      "Created a chunk of size 1180, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1050, which is longer than the specified 1000\n",
      "Created a chunk of size 1363, which is longer than the specified 1000\n",
      "Created a chunk of size 1172, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1217, which is longer than the specified 1000\n",
      "Created a chunk of size 1199, which is longer than the specified 1000\n",
      "Created a chunk of size 1398, which is longer than the specified 1000\n",
      "Created a chunk of size 1312, which is longer than the specified 1000\n",
      "Created a chunk of size 1193, which is longer than the specified 1000\n",
      "Created a chunk of size 1147, which is longer than the specified 1000\n",
      "Created a chunk of size 1153, which is longer than the specified 1000\n",
      "Created a chunk of size 1858, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating vector store chroma_db_char ---\n",
      "--- Finished creating vector store chroma_db_char ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Character-based Splitting\n",
    "# Splits text into chunks based on a specified number of characters.\n",
    "# Useful for consistent chunk sizes regardless of content structure.\n",
    "print(\"\\n--- Using Character-based Splitting ---\")\n",
    "char_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "char_docs = char_splitter.split_documents(documents)\n",
    "create_vector_store(char_docs, \"chroma_db_char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Sentence-based Splitting ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Siddharth\\.conda\\envs\\repgpt\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Siddharth\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating vector store chroma_db_sent ---\n",
      "--- Finished creating vector store chroma_db_sent ---\n"
     ]
    }
   ],
   "source": [
    "# 2. Sentence-based Splitting\n",
    "# Splits text into chunks based on sentences, ensuring chunks end at sentence boundaries.\n",
    "# Ideal for maintaining semantic coherence within chunks.\n",
    "print(\"\\n--- Using Sentence-based Splitting ---\")\n",
    "sent_splitter = SentenceTransformersTokenTextSplitter(chunk_size=1000)\n",
    "sent_docs = sent_splitter.split_documents(documents)\n",
    "create_vector_store(sent_docs, \"chroma_db_sent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Token-based Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_token ---\n",
      "--- Finished creating vector store chroma_db_token ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Token-based Splitting\n",
    "# Splits text into chunks based on tokens (words or subwords), using tokenizers like GPT-2.\n",
    "# Useful for transformer models with strict token limits.\n",
    "print(\"\\n--- Using Token-based Splitting ---\")\n",
    "token_splitter = TokenTextSplitter(chunk_overlap=0, chunk_size=512)\n",
    "token_docs = token_splitter.split_documents(documents)\n",
    "create_vector_store(token_docs, \"chroma_db_token\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Recursive Character-based Splitting ---\n",
      "\n",
      "--- Creating vector store chroma_db_rec_char ---\n",
      "--- Finished creating vector store chroma_db_rec_char ---\n"
     ]
    }
   ],
   "source": [
    "# 4. Recursive Character-based Splitting\n",
    "# Attempts to split text at natural boundaries (sentences, paragraphs) within character limit.\n",
    "# Balances between maintaining coherence and adhering to character limits.\n",
    "print(\"\\n--- Using Recursive Character-based Splitting ---\")\n",
    "rec_char_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100)\n",
    "rec_char_docs = rec_char_splitter.split_documents(documents)\n",
    "create_vector_store(rec_char_docs, \"chroma_db_rec_char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Custom Splitting ---\n"
     ]
    }
   ],
   "source": [
    "# 5. Custom Splitting\n",
    "# Allows creating custom splitting logic based on specific requirements.\n",
    "# Useful for documents with unique structure that standard splitters can't handle.\n",
    "print(\"\\n--- Using Custom Splitting ---\")\n",
    "class CustomTextSplitter(TextSplitter):\n",
    "    def split_text(self, text):\n",
    "        # Custom logic for splitting text\n",
    "        return text.split(\"\\n\\n\")  # Example: split by paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating vector store chroma_db_custom ---\n",
      "--- Finished creating vector store chroma_db_custom ---\n"
     ]
    }
   ],
   "source": [
    "#Store in custom chroma db\n",
    "custom_splitter = CustomTextSplitter()\n",
    "custom_docs = custom_splitter.split_documents(documents)\n",
    "create_vector_store(custom_docs, \"chroma_db_custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query a vector store\n",
    "def query_vector_store(store_name, query):\n",
    "    persistent_directory=os.path.join(db_dir, store_name)\n",
    "    if os.path.exists(persistent_directory):\n",
    "        print(f\"\\n----Queying the vector store {store_name}----\")\n",
    "        db = Chroma(\n",
    "            persist_directory=persistent_directory, embedding_function=embeddings\n",
    "        )\n",
    "        retriever = db.as_retriever(\n",
    "            search_type = \"similarity\",\n",
    "            search_kwargs={\"k\":3},\n",
    "            \n",
    "        )\n",
    "        relevant_docs = retriever.invoke(query)\n",
    "        # Display the relevant results with metadata\n",
    "        print(f\"\\n-- Relevant Documents for {store_name}---\")\n",
    "        for i, doc in enumerate(relevant_docs, 1):\n",
    "            print(f\"Document {i} \\n{doc.page_content}\\n\")\n",
    "            if doc.metadata:\n",
    "                print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Vector store {store_name} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's question\n",
    "query = \"What is model distillation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Queying the vector store chroma_db_char----\n",
      "\n",
      "-- Relevant Documents for chroma_db_char---\n",
      "Document 1 \n",
      "Model Distillation\n",
      "Model distillation (also called knowledge distillation) is a method in which a small\n",
      "model (student) is trained to mimic a larger model (teacher) (Hinton et al., 2015).\n",
      "The knowledge of the big model is distilled into the small model, hence the term dis‐\n",
      "tillation.\n",
      "Traditionally, the goal of model distillation is to produce smaller models for deploy‐\n",
      "ment. Deploying a big model can be resource-intensive. Distillation can produce a\n",
      "smaller, faster student model that retains performance comparable to the teacher. For\n",
      "example, DistilBERT, a model distilled from BERT, reduces the size of a BERT model\n",
      "by 40% while retaining 97% of its language comprehension capabilities and being\n",
      "60% faster (Sanh et al., 2019).\n",
      "The student model can be trained from scratch like DistilBERT or finetuned from a\n",
      "pre-trained model like Alpaca. In 2023, Taori et al. finetuned Llama-7B, the 7-billionparameter version of Llama, on examples generated by text-davinci-003, a 175billion-parameter model. The resulting model, Alpaca, behaves similarly to textdavinci-003, while being 4% the size of the teacher model.\n",
      "Not all models can be distilled. Many model licenses prohibit using\n",
      "their outputs to train other models, particularly to train competing\n",
      "models.\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 2 \n",
      "tion, as discussed in Chapter 2.\n",
      "\n",
      "Prompt Engineering Best Practices\n",
      "\n",
      "|\n",
      "\n",
      "223\n",
      "\n",
      "\fYou can either provide the model with the necessary context or give it tools to gather\n",
      "context. The process of gathering necessary context for a given query is called context\n",
      "construction. Context construction tools include data retrieval, such as in a RAG\n",
      "pipeline, and web search. These tools are discussed in Chapter 6.\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 3 \n",
      "Term-based retrieval\n",
      "Given a query, the most straightforward way to find relevant documents is with key‐\n",
      "words. Some people call this approach lexical retrieval. For example, given the query\n",
      "“AI engineering”, the model will retrieve all the documents that contain “AI engi‐\n",
      "neering”. However, this approach has two problems:\n",
      "• Many documents might contain the given term, and your model might not have\n",
      "sufficient context space to include all of them as context. A heuristic is to include\n",
      "the documents that contain the term the greatest number of times. The assump‐\n",
      "tion is that the more a term appears in a document, the more relevant this docu‐\n",
      "ment is to this term. The number of times a term appears in a document is called\n",
      "term frequency (TF).\n",
      "• A prompt can be long and contain many terms. Some are more important than\n",
      "others. For example, the prompt “Easy-to-follow recipes for Vietnamese food to\n",
      "cook at home” contains nine terms: easy-to-follow, recipes, for, vietnamese, food,\n",
      "258\n",
      "\n",
      "|\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "\n",
      "----Queying the vector store chroma_db_sent----\n",
      "\n",
      "-- Relevant Documents for chroma_db_sent---\n",
      "Document 1 \n",
      "##ual models domain - specific models modeling model architecture model size post - training supervised finetuning preference finetuning sampling sampling fundamentals sampling strategies test time compute structured outputs the probabilistic nature of ai summary 50 51 56 58 58 67 78 80 83 88 88 90 96 99 105 111 3. evaluation methodology................................................... 113 challenges of evaluating foundation models understanding language modeling metrics entropy cross entropy bits - per - character and bits - per - byte perplexity perplexity interpretation and use cases exact evaluation functional correctness similarity measurements against reference data introduction to embedding ai as a judge why ai as a judge? how to use ai as a judge limitations of ai as a judge what models can act as judges? ranking models with comparative evaluation challenges of comparative evaluation the future of comparative evaluation summary vi | table of contents 114 118 119 120 121 121 122 125 126 127 134 136 137 138 141 145 148 152 155 156 4. evaluate ai systems....................................................... 159 evaluation criteria domain - specific capability generation capability instruction - following capability cost and latency model selection model selection workflow model build versus buy navigate public benchmarks design your evaluation pipeline step 1. evaluate all components in a system step 2. create an evaluation guideline step 3. define evaluation methods and data summary 160 161 163 172 177 179 179 181 191 200 200 202 204 208 5. prompt engineering............\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 2 \n",
      "in this work is at your own risk. if any code samples or other technology this work contains or describes is subject to open source licenses or the intellectual property rights of others, it is your responsibility to ensure that your use thereof complies with such licenses and / or rights. 978 - 1 - 098 - 16630 - 4 [ lsi ] table of contents preface....................................................................... xi 1. introduction to building ai applications with foundation models.................. 1 the rise of ai engineering from language models to large language models from large language models to foundation models from foundation models to ai engineering foundation model use cases coding image and video production writing education conversational bots information aggregation data organization workflow automation planning ai applications use case evaluation setting expectations milestone planning maintenance the ai engineering stack three layers of the ai stack ai engineering versus ml engineering ai engineering versus full - stack engineering summary 2 2 8 12 16 20 22 22 24 26 26 27 28 28 29 32 33 34 35 37 39 46 47 v 2. understanding foundation models........................................... 49 training data multilingual models domain - specific models modeling model architecture model size post - training supervised finetuning preference finetuning sampling sampling fundamentals sampling strategies test time compute structured outputs the probabilistic nature of ai summary 50 51 56 58 58 67 78 80\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 3 \n",
      "skip ahead if it feels a little too in the weeds! preface | xv navigating this book this book is structured to follow the typical process for developing an ai application. here ’ s what this typical process looks like and how each chapter fits into the process. because this book is modular, you ’ re welcome to skip any section that you ’ re already familiar with or that is less relevant to you. before deciding to build an ai application, it ’ s necessary to understand what this pro ‐ cess involves and answer questions such as : is this application necessary? is ai needed? do i have to build this application myself? the first chapter of the book helps you answer these questions. it also covers a range of successful use cases to give a sense of what foundation models can do. while an ml background is not necessary to build ai applications, understanding how a foundation model works under the hood is useful to make the most out of it. chapter 2 analyzes the making of a foundation model and the design decisions with significant impacts on downstream applications, including its training data recipe, model architectures and scales, and how the model is trained to align to human pref ‐ erence. it then discusses how a model generates a response, which helps explain the model ’ s seemingly baffling behaviors, like inconsistency and hallucinations. chang ‐ ing the generation setting of a model is also often a cheap and easy way to signifi ‐ cantly boost the model ’ s performance. once you ’ ve committed to building an application with foundation models, evalua ‐ tion will be an integral part of every step along the way. evaluation is one of the hard ‐ est, if not the hardest, challenges of ai engineering. this book dedicates two chapters, chapters 3 and 4, to explore different evaluation methods and how to use them to create a reliable and systematic evaluation pipeline\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "\n",
      "----Queying the vector store chroma_db_token----\n",
      "\n",
      "-- Relevant Documents for chroma_db_token---\n",
      "Document 1 \n",
      " or describes is subject to open source\n",
      "licenses or the intellectual property rights of others, it is your responsibility to ensure that your use\n",
      "thereof complies with such licenses and/or rights.\n",
      "\n",
      "978-1-098-16630-4\n",
      "[LSI]\n",
      "\n",
      "\fTable of Contents\n",
      "\n",
      "Preface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi\n",
      "1. Introduction to Building AI Applications with Foundation Models. . . . . . . . . . . . . . . . . . 1\n",
      "The Rise of AI Engineering\n",
      "From Language Models to Large Language Models\n",
      "From Large Language Models to Foundation Models\n",
      "From Foundation Models to AI Engineering\n",
      "Foundation Model Use Cases\n",
      "Coding\n",
      "Image and Video Production\n",
      "Writing\n",
      "Education\n",
      "Conversational Bots\n",
      "Information Aggregation\n",
      "Data Organization\n",
      "Workflow Automation\n",
      "Planning AI Applications\n",
      "Use Case Evaluation\n",
      "Setting Expectations\n",
      "Milestone Planning\n",
      "Maintenance\n",
      "The AI Engineering Stack\n",
      "Three Layers of the AI Stack\n",
      "AI Engineering Versus ML Engineering\n",
      "AI Engineering Versus Full-Stack Engineering\n",
      "Summary\n",
      "\n",
      "2\n",
      "2\n",
      "8\n",
      "12\n",
      "16\n",
      "20\n",
      "22\n",
      "22\n",
      "24\n",
      "26\n",
      "26\n",
      "27\n",
      "28\n",
      "28\n",
      "29\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "37\n",
      "39\n",
      "46\n",
      "47\n",
      "\n",
      "v\n",
      "\n",
      "\f2. Understanding Foundation Models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n",
      "Training Data\n",
      "Multilingual Models\n",
      "Domain-Specific Models\n",
      "Modeling\n",
      "Model Architecture\n",
      "Model Size\n",
      "Post-Training\n",
      "Supervised Finetuning\n",
      "Preference Finetuning\n",
      "Sampling\n",
      "Sampling Fundamentals\n",
      "Sampling Strategies\n",
      "Test Time Compute\n",
      "Structured Outputs\n",
      "The Probabilistic Nature of AI\n",
      "Summary\n",
      "\n",
      "50\n",
      "51\n",
      "56\n",
      "58\n",
      "58\n",
      "67\n",
      "78\n",
      "80\n",
      "83\n",
      "88\n",
      "88\n",
      "90\n",
      "96\n",
      "99\n",
      "105\n",
      "111\n",
      "\n",
      "3. Evaluation Methodology. . . . . . . . . . . . . . . . . .\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 2 \n",
      ".\n",
      "I love getting to the bottom of things, so some sections dive a bit deeper into the tech‐\n",
      "nical side. While many early readers like the detail, it might not be for everyone. I’ll\n",
      "give you a heads-up before things get too technical. Feel free to skip ahead if it feels a\n",
      "little too in the weeds!\n",
      "\n",
      "Preface\n",
      "\n",
      "|\n",
      "\n",
      "xv\n",
      "\n",
      "\fNavigating This Book\n",
      "This book is structured to follow the typical process for developing an AI application.\n",
      "Here’s what this typical process looks like and how each chapter fits into the process.\n",
      "Because this book is modular, you’re welcome to skip any section that you’re already\n",
      "familiar with or that is less relevant to you.\n",
      "Before deciding to build an AI application, it’s necessary to understand what this pro‐\n",
      "cess involves and answer questions such as: Is this application necessary? Is AI\n",
      "needed? Do I have to build this application myself? The first chapter of the book\n",
      "helps you answer these questions. It also covers a range of successful use cases to give\n",
      "a sense of what foundation models can do.\n",
      "While an ML background is not necessary to build AI applications, understanding\n",
      "how a foundation model works under the hood is useful to make the most out of it.\n",
      "Chapter 2 analyzes the making of a foundation model and the design decisions with\n",
      "significant impacts on downstream applications, including its training data recipe,\n",
      "model architectures and scales, and how the model is trained to align to human pref‐\n",
      "erence. It then discusses how a model generates a response, which helps explain the\n",
      "model’s seemingly baffling behaviors, like inconsistency and hallucinations. Chang‐\n",
      "ing the generation setting of a model is also often a cheap and easy way to signifi‐\n",
      "cantly boost the model’s performance.\n",
      "Once you’ve committed to building an application with foundation models, evalua‐\n",
      "tion will be an integral part of every step along the way. Evaluation is one of the hard‐\n",
      "est, if not the hardest, challenges of AI engineering. This book dedicates two chapters,\n",
      "Chapters 3 and 4, to explore different evaluation methods and how to use them to\n",
      "create a reliable and systematic evaluation pipeline for your application.\n",
      "Given a query, the quality of a model’s response depends on the following aspects\n",
      "(outside of the model’s generation setting):\n",
      "• The\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 3 \n",
      "\n",
      "Data Curation\n",
      "Data Quality\n",
      "Data Coverage\n",
      "Data Quantity\n",
      "Data Acquisition and Annotation\n",
      "Data Augmentation and Synthesis\n",
      "Why Data Synthesis\n",
      "Traditional Data Synthesis Techniques\n",
      "AI-Powered Data Synthesis\n",
      "Model Distillation\n",
      "Data Processing\n",
      "Inspect Data\n",
      "Deduplicate Data\n",
      "Clean and Filter Data\n",
      "\n",
      "viii\n",
      "\n",
      "|\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "365\n",
      "368\n",
      "369\n",
      "372\n",
      "377\n",
      "380\n",
      "381\n",
      "383\n",
      "386\n",
      "395\n",
      "396\n",
      "397\n",
      "399\n",
      "401\n",
      "\n",
      "\fFormat Data\n",
      "Summary\n",
      "\n",
      "401\n",
      "403\n",
      "\n",
      "9. Inference Optimization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405\n",
      "Understanding Inference Optimization\n",
      "Inference Overview\n",
      "Inference Performance Metrics\n",
      "AI Accelerators\n",
      "Inference Optimization\n",
      "Model Optimization\n",
      "Inference Service Optimization\n",
      "Summary\n",
      "\n",
      "406\n",
      "406\n",
      "412\n",
      "419\n",
      "426\n",
      "426\n",
      "440\n",
      "447\n",
      "\n",
      "10. AI Engineering Architecture and User Feedback. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449\n",
      "AI Engineering Architecture\n",
      "Step 1. Enhance Context\n",
      "Step 2. Put in Guardrails\n",
      "Step 3. Add Model Router and Gateway\n",
      "Step 4. Reduce Latency with Caches\n",
      "Step 5. Add Agent Patterns\n",
      "Monitoring and Observability\n",
      "AI Pipeline Orchestration\n",
      "User Feedback\n",
      "Extracting Conversational Feedback\n",
      "Feedback Design\n",
      "Feedback Limitations\n",
      "Summary\n",
      "\n",
      "449\n",
      "450\n",
      "451\n",
      "456\n",
      "460\n",
      "463\n",
      "465\n",
      "472\n",
      "474\n",
      "475\n",
      "480\n",
      "490\n",
      "492\n",
      "\n",
      "Epilogue. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 495\n",
      "Index. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "\n",
      "----Queying the vector store chroma_db_rec_char----\n",
      "\n",
      "-- Relevant Documents for chroma_db_rec_char---\n",
      "Document 1 \n",
      "Model Distillation\n",
      "Model distillation (also called knowledge distillation) is a method in which a small\n",
      "model (student) is trained to mimic a larger model (teacher) (Hinton et al., 2015).\n",
      "The knowledge of the big model is distilled into the small model, hence the term dis‐\n",
      "tillation.\n",
      "Traditionally, the goal of model distillation is to produce smaller models for deploy‐\n",
      "ment. Deploying a big model can be resource-intensive. Distillation can produce a\n",
      "smaller, faster student model that retains performance comparable to the teacher. For\n",
      "example, DistilBERT, a model distilled from BERT, reduces the size of a BERT model\n",
      "by 40% while retaining 97% of its language comprehension capabilities and being\n",
      "60% faster (Sanh et al., 2019).\n",
      "The student model can be trained from scratch like DistilBERT or finetuned from a\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 2 \n",
      "lucinations and inconsistencies, but choosing the right sampling strategy can also sig‐\n",
      "nificantly boost a model’s performance with relatively little effort. For this reason,\n",
      "sampling is the section that I was the most excited to write about in this chapter.\n",
      "Concepts covered in this chapter are fundamental for understanding the rest of the\n",
      "book. However, because these concepts are fundamental, you might already be famil‐\n",
      "iar with them. Feel free free to skip any concept that you’re confident about. If you\n",
      "encounter a confusing concept later on, you can revisit this chapter.\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 3 \n",
      "of data to train future models (discussed together with other data synthesis topics\n",
      "in Chapter 8). A use case of data synthesis is model distillation: teaching a\n",
      "student (typically a much smaller model) to mimic the behavior of a teacher\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "\n",
      "----Queying the vector store chroma_db_custom----\n",
      "\n",
      "-- Relevant Documents for chroma_db_custom---\n",
      "Document 1 \n",
      "\fdesign. There are so many ways people construct and evaluate data. I hope that the\n",
      "range of data synthesis and verification techniques discussed in this chapter will give\n",
      "you inspiration for how to design your dataset.\n",
      "Let’s say that you’ve curated a wonderful dataset that allows you to train an amazing\n",
      "model. How should you serve this model? The next chapter will discuss how to opti‐\n",
      "mize inference for latency and cost.\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 2 \n",
      "\fAPIs (see open source models, model APIs ver‐\n",
      "sus)\n",
      "application building, 1-48\n",
      "application planning, 28-35\n",
      "maintenance, 34\n",
      "milestone planning, 33\n",
      "set expectations, 32\n",
      "use case evaluation, 29-32\n",
      "engineering stack, 35-47\n",
      "AI engineering versus ML engineering,\n",
      "39-46\n",
      "application development, 44-46\n",
      "full-stack engineering versus, 46\n",
      "three layers of AI stack, 37-39\n",
      "foundation model use cases, 16-28\n",
      "coding, 20-22\n",
      "conversational bots, 26\n",
      "data organization, 27\n",
      "education, 24\n",
      "image and video production, 22\n",
      "information aggregation, 26\n",
      "workflow automation, 28\n",
      "writing, 22-24\n",
      "rise of AI engineering, 2-14\n",
      "foundation models to AI engineering,\n",
      "12-14\n",
      "application development, 37, 44-46\n",
      "AI interface, 45\n",
      "evaluation, 44\n",
      "prompt engineering and context construc‐\n",
      "tion, 45\n",
      "application planning, 28-35\n",
      "maintenance, 34\n",
      "milestone planning, 33\n",
      "set expectations, 32\n",
      "use case evaluation, 29-32\n",
      "approximate nearest neighbor (ANN), 262\n",
      "approximate string matching, 130\n",
      "ARC-C, 192\n",
      "attention mechanisms, 60-62\n",
      "attention modules, 62\n",
      "MLP modules, 62\n",
      "optimization, 433-436\n",
      "attention mechanism redesign, 435\n",
      "wiring kernels for attention computa‐\n",
      "tion, 436\n",
      "redesign, 435\n",
      "attention modules, 62\n",
      "augmentation of data\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n",
      "Document 3 \n",
      "Step 5. Add Agent Patterns\n",
      "The applications discussed so far are still fairly simple. Each query follows a sequen‐\n",
      "tial flow. However, as discussed in Chapter 6, an application flow can be more com‐\n",
      "plex with loops, parallel execution, and conditional branching. Agentic patterns,\n",
      "discussed in Chapter 6, can help you build complex applications. For example, after\n",
      "the system generates an output, it might determine that it hasn’t accomplished the\n",
      "task and that it needs to perform another retrieval to gather more information. The\n",
      "original response, together with the newly retrieved context, is passed into the same\n",
      "model or a different one. This creates a loop, as shown in Figure 10-9.\n",
      "\n",
      "Source: d:\\Terragent\\GenAI Experiments\\Langchain Experiments\\books\\AI_Engineering.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query each vector store\n",
    "query_vector_store(\"chroma_db_char\", query)\n",
    "query_vector_store(\"chroma_db_sent\", query)\n",
    "query_vector_store(\"chroma_db_token\", query)\n",
    "query_vector_store(\"chroma_db_rec_char\", query)\n",
    "query_vector_store(\"chroma_db_custom\", query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Rag Retriever Deep Dive\n",
    "\n",
    "\n",
    "Types of search available:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Similarity Search**\n",
    "- **Purpose**: Retrieves documents most similar to the query based on vector embeddings.\n",
    "- **How it works**: Computes the cosine similarity (or a similar metric) between the query vector and document vectors.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  retriever = db.as_retriever()\n",
    "  results = retriever.invoke(query)\n",
    "  ```\n",
    "- Use case: General-purpose searches to retrieve the closest matching documents.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Similarity Search with a Score Threshold**\n",
    "- **Purpose**: Retrieves documents only if their similarity score meets a minimum threshold.\n",
    "- **How it works**: Filters out less relevant results to ensure only highly similar documents are returned.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  retriever = db.as_retriever(\n",
    "      search_type=\"similarity_score_threshold\",\n",
    "      search_kwargs={\"score_threshold\": 0.5}\n",
    "  )\n",
    "  ```\n",
    "- Use case: High-precision searches where only very relevant documents are needed.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Top-K Similarity Search**\n",
    "- **Purpose**: Retrieves the top `k` most similar documents to the query.\n",
    "- **How it works**: Sorts all documents by similarity score and returns the top `k` matches.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  retriever = db.as_retriever(\n",
    "      search_kwargs={\"k\": 3}  # Retrieves top 3 most similar documents\n",
    "  )\n",
    "  ```\n",
    "- Use case: Focused searches with a limited number of results.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. MMR (Maximal Marginal Relevance) Search**\n",
    "- **Purpose**: Balances relevance and diversity of the results.\n",
    "- **How it works**: Selects results based on both similarity to the query and dissimilarity to other results.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  retriever = db.as_retriever(\n",
    "      search_type=\"mmr\",\n",
    "      search_kwargs={\"k\": 3, \"lambda\": 0.5}  # `lambda` controls relevance vs diversity\n",
    "  )\n",
    "  ```\n",
    "- Use case: When you want a diverse set of results while keeping relevance.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Filtered Search**\n",
    "- **Purpose**: Retrieves documents that meet specific metadata or attribute-based conditions.\n",
    "- **How it works**: Filters documents based on custom metadata (e.g., source, date, category).\n",
    "- **Example**:\n",
    "  ```python\n",
    "  retriever = db.as_retriever(\n",
    "      search_type=\"filter\",\n",
    "      search_kwargs={\"filter\": {\"source\": \"report\"}}\n",
    "  )\n",
    "  ```\n",
    "- Use case: Use cases requiring strict filtering of results (e.g., documents from a specific source or time period).\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Hybrid Search**\n",
    "- **Purpose**: Combines multiple search methods, such as lexical (keyword) search and vector similarity.\n",
    "- **How it works**: Merges results from different search techniques for better precision and recall.\n",
    "- **Use case**: When you want to leverage both embeddings and keyword-based searches.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you'd like to go deeper into any of these or need examples with your use case in mind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the text files and the persistent directory\n",
    "current_dir = os.path.abspath(\"\")\n",
    "db_dir = os.path.join(current_dir, \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query a vector store with different search types and parameters\n",
    "def query_vector_store(\n",
    "        store_name, query, embedding_function, search_type, search_kwargs\n",
    "):\n",
    "    if os.path.exists(persistent_directory):\n",
    "        print(f\"\\n--Querying the vector store {store_name}------\")\n",
    "        db = Chroma(\n",
    "            persist_directory=persistent_directory,\n",
    "            embedding_function=embedding_function\n",
    "        )\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=search_type,\n",
    "            search_kwargs=search_kwargs,\n",
    "        )\n",
    "        relevant_docs = retriever.invoke(query)\n",
    "        # Display the relevant results with metadata\n",
    "        print(f\"\\n--- Relevant Documents for {store_name} ---\")\n",
    "        for i, doc in enumerate(relevant_docs, 1):\n",
    "            print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "            if doc.metadata:\n",
    "                print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n",
    "    else:\n",
    "        print(f\"Vector store {store_name} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user query\n",
    "query = \"What is llm model distillation?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Similarity Search ---\n",
      "\n",
      "--Querying the vector store chroma_db_with_metadata------\n",
      "\n",
      "--- Relevant Documents for chroma_db_with_metadata ---\n",
      "Document 1:\n",
      "You can either provide the model with the necessary context or give it tools to gather\n",
      "context. The process of gathering necessary context for a given query is called context\n",
      "construction. Context construction tools include data retrieval, such as in a RAG\n",
      "pipeline, and web search. These tools are discussed in Chapter 6.\n",
      "\n",
      "Source: AI_Engineering.txt\n",
      "\n",
      "Document 2:\n",
      "Term-based retrieval\n",
      "Given a query, the most straightforward way to find relevant documents is with key‐\n",
      "words. Some people call this approach lexical retrieval. For example, given the query\n",
      "“AI engineering”, the model will retrieve all the documents that contain “AI engi‐\n",
      "neering”. However, this approach has two problems:\n",
      "• Many documents might contain the given term, and your model might not have\n",
      "sufficient context space to include all of them as context. A heuristic is to include\n",
      "the documents that contain the term the greatest number of times. The assump‐\n",
      "tion is that the more a term appears in a document, the more relevant this docu‐\n",
      "ment is to this term. The number of times a term appears in a document is called\n",
      "term frequency (TF).\n",
      "• A prompt can be long and contain many terms. Some are more important than\n",
      "others. For example, the prompt “Easy-to-follow recipes for Vietnamese food to\n",
      "cook at home” contains nine terms: easy-to-follow, recipes, for, vietnamese, food,\n",
      "258\n",
      "\n",
      "|\n",
      "\n",
      "Source: AI_Engineering.txt\n",
      "\n",
      "Document 3:\n",
      "What This Book Is About\n",
      "This book provides a framework for adapting foundation models, which include both\n",
      "large language models (LLMs) and large multimodal models (LMMs), to specific\n",
      "applications.\n",
      "There are many different ways to build an application. This book outlines various\n",
      "solutions and also raises questions you can ask to evaluate the best solution for your\n",
      "needs. Some of the many questions that this book can help you answer are:\n",
      "• Should I build this AI application?\n",
      "• How do I evaluate my application? Can I use AI to evaluate AI outputs?\n",
      "• What causes hallucinations? How do I detect and mitigate hallucinations?\n",
      "• What are the best practices for prompt engineering?\n",
      "• Why does RAG work? What are the strategies for doing RAG?\n",
      "xii\n",
      "\n",
      "|\n",
      "\n",
      "Preface\n",
      "\n",
      "Source: AI_Engineering.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showcase different retrieval methods\n",
    "\n",
    "# 1. Similarity Search\n",
    "# This method retrieves documents based on vector similarity.\n",
    "# It finds the most similar documents to the query vector based on cosine similarity.\n",
    "# Use this when you want to retrieve the top k most similar documents.\n",
    "print(\"\\n--- Using Similarity Search ---\")\n",
    "query_vector_store(\"chroma_db_with_metadata\", query,\n",
    "                   embeddings, \"similarity\", {\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Max Marginal Relevance (MMR) ---\n",
      "\n",
      "--Querying the vector store chroma_db_with_metadata------\n",
      "\n",
      "--- Relevant Documents for chroma_db_with_metadata ---\n",
      "Document 1:\n",
      "You can either provide the model with the necessary context or give it tools to gather\n",
      "context. The process of gathering necessary context for a given query is called context\n",
      "construction. Context construction tools include data retrieval, such as in a RAG\n",
      "pipeline, and web search. These tools are discussed in Chapter 6.\n",
      "\n",
      "Source: AI_Engineering.txt\n",
      "\n",
      "Document 2:\n",
      "364\n",
      "\n",
      "|\n",
      "\n",
      "Chapter 8: Dataset Engineering\n",
      "\n",
      "\fThe model-centric and data-centric division helps guide research. In reality, however,\n",
      "meaningful technological progress often requires investment in both model and data\n",
      "improvements.\n",
      "\n",
      "Source: AI_Engineering.txt\n",
      "\n",
      "Document 3:\n",
      "430\n",
      "\n",
      "|\n",
      "\n",
      "Chapter 9: Inference Optimization\n",
      "\n",
      "\fFigure 9-10. Two examples of inference with reference. The text spans that are success‐\n",
      "fully copied from the input are in red and green. Image from Yang et al. (2023). The\n",
      "image is licensed under CC BY 4.0.\n",
      "\n",
      "Inference Optimization\n",
      "\n",
      "|\n",
      "\n",
      "431\n",
      "\n",
      "Source: AI_Engineering.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Max Marginal Relevance (MMR)\n",
    "# This method balances between selecting documents that are relevant to the query and diverse among themselves.\n",
    "# 'fetch_k' specifies the number of documents to initially fetch based on similarity.\n",
    "# 'lambda_mult' controls the diversity of the results: 1 for minimum diversity, 0 for maximum.\n",
    "# Use this when you want to avoid redundancy and retrieve diverse yet relevant documents.\n",
    "# Note: Relevance measures how closely documents match the query.\n",
    "# Note: Diversity ensures that the retrieved documents are not too similar to each other,\n",
    "#       providing a broader range of information.\n",
    "print(\"\\n--- Using Max Marginal Relevance (MMR) ---\")\n",
    "query_vector_store(\n",
    "    \"chroma_db_with_metadata\",\n",
    "    query,\n",
    "    embeddings,\n",
    "    \"mmr\",\n",
    "    {\"k\": 3, \"fetch_k\": 20, \"lambda_mult\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using Similarity Score Threshold ---\n",
      "\n",
      "--Querying the vector store chroma_db_with_metadata------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Siddharth\\.conda\\envs\\repgpt\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1077: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'AI_Engineering.txt'}, page_content='You can either provide the model with the necessary context or give it tools to gather\\ncontext. The process of gathering necessary context for a given query is called context\\nconstruction. Context construction tools include data retrieval, such as in a RAG\\npipeline, and web search. These tools are discussed in Chapter 6.'), -21.977169754351475), (Document(metadata={'source': 'AI_Engineering.txt'}, page_content='Term-based retrieval\\nGiven a query, the most straightforward way to find relevant documents is with key‐\\nwords. Some people call this approach lexical retrieval. For example, given the query\\n“AI engineering”, the model will retrieve all the documents that contain “AI engi‐\\nneering”. However, this approach has two problems:\\n• Many documents might contain the given term, and your model might not have\\nsufficient context space to include all of them as context. A heuristic is to include\\nthe documents that contain the term the greatest number of times. The assump‐\\ntion is that the more a term appears in a document, the more relevant this docu‐\\nment is to this term. The number of times a term appears in a document is called\\nterm frequency (TF).\\n• A prompt can be long and contain many terms. Some are more important than\\nothers. For example, the prompt “Easy-to-follow recipes for Vietnamese food to\\ncook at home” contains nine terms: easy-to-follow, recipes, for, vietnamese, food,\\n258\\n\\n|'), -25.434352331727673), (Document(metadata={'source': 'AI_Engineering.txt'}, page_content='Navigating This Book\\nThis book is structured to follow the typical process for developing an AI application.\\nHere’s what this typical process looks like and how each chapter fits into the process.\\nBecause this book is modular, you’re welcome to skip any section that you’re already\\nfamiliar with or that is less relevant to you.\\nBefore deciding to build an AI application, it’s necessary to understand what this pro‐\\ncess involves and answer questions such as: Is this application necessary? Is AI\\nneeded? Do I have to build this application myself? The first chapter of the book\\nhelps you answer these questions. It also covers a range of successful use cases to give\\na sense of what foundation models can do.\\nWhile an ML background is not necessary to build AI applications, understanding\\nhow a foundation model works under the hood is useful to make the most out of it.\\nChapter 2 analyzes the making of a foundation model and the design decisions with\\nsignificant impacts on downstream applications, including its training data recipe,\\nmodel architectures and scales, and how the model is trained to align to human pref‐\\nerence. It then discusses how a model generates a response, which helps explain the\\nmodel’s seemingly baffling behaviors, like inconsistency and hallucinations. Chang‐\\ning the generation setting of a model is also often a cheap and easy way to signifi‐\\ncantly boost the model’s performance.\\nOnce you’ve committed to building an application with foundation models, evalua‐\\ntion will be an integral part of every step along the way. Evaluation is one of the hard‐\\nest, if not the hardest, challenges of AI engineering. This book dedicates two chapters,\\nChapters 3 and 4, to explore different evaluation methods and how to use them to\\ncreate a reliable and systematic evaluation pipeline for your application.\\nGiven a query, the quality of a model’s response depends on the following aspects\\n(outside of the model’s generation setting):\\n• The instructions for how the model should behave\\n• The context the model can use to respond to the query\\n• The model itself\\nThe next three chapters of the book focus on how to optimize each of these aspects to\\nimprove a model’s performance for an application. Chapter 5 covers prompt engi‐\\nneering, starting with what a prompt is, why prompt engineering works, and prompt\\nengineering best practices. It then discusses how bad actors can exploit your applica‐\\ntion with prompt attacks and how to defend your application against them.\\nChapter 6 explores why context is important for a model to generate accurate respon‐\\nses. It zooms into two major application patterns for context construction: RAG and\\nagentic. The RAG pattern is better understood and has proven to work well in\\nxvi'), -25.936017165833565)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents for chroma_db_with_metadata ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Similarity Score Threshold\n",
    "# This method retrieves documents that exceed a certain similarity score threshold.\n",
    "# 'score_threshold' sets the minimum similarity score a document must have to be considered relevant.\n",
    "# Use this when you want to ensure that only highly relevant documents are retrieved, filtering out less relevant ones.\n",
    "print(\"\\n--- Using Similarity Score Threshold ---\")\n",
    "query_vector_store(\n",
    "    \"chroma_db_with_metadata\",\n",
    "    query,\n",
    "    embeddings,\n",
    "    \"similarity_score_threshold\",\n",
    "    {\"k\": 3, \"score_threshold\": 0.1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. RAG One Off Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the text files and the persistent directory\n",
    "current_dir = os.path.abspath(\"\")\n",
    "db_dir = os.path.join(current_dir, \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(persist_directory=persistent_directory, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is a LLM evaluation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "relevant_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Relevant Documents-----\n",
      "Document 1: \n",
      " Chapter 3: Evaluation Methodology\n",
      "\n",
      "Document 2: \n",
      " 3. Evaluation Methodology. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\n",
      "Challenges of Evaluating Foundation Models\n",
      "Understanding Language Modeling Metrics\n",
      "Entropy\n",
      "Cross Entropy\n",
      "Bits-per-Character and Bits-per-Byte\n",
      "Perplexity\n",
      "Perplexity Interpretation and Use Cases\n",
      "Exact Evaluation\n",
      "Functional Correctness\n",
      "Similarity Measurements Against Reference Data\n",
      "Introduction to Embedding\n",
      "AI as a Judge\n",
      "Why AI as a Judge?\n",
      "How to Use AI as a Judge\n",
      "Limitations of AI as a Judge\n",
      "What Models Can Act as Judges?\n",
      "Ranking Models with Comparative Evaluation\n",
      "Challenges of Comparative Evaluation\n",
      "The Future of Comparative Evaluation\n",
      "Summary\n",
      "\n",
      "vi\n",
      "\n",
      "|\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "114\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "121\n",
      "122\n",
      "125\n",
      "126\n",
      "127\n",
      "134\n",
      "136\n",
      "137\n",
      "138\n",
      "141\n",
      "145\n",
      "148\n",
      "152\n",
      "155\n",
      "156\n",
      "\n",
      "Document 3: \n",
      " 4 Textual entailment is also known as natural language inference (NLI).\n",
      "\n",
      "168\n",
      "\n",
      "|\n",
      "\n",
      "Chapter 4: Evaluate AI Systems\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"\\n----Relevant Documents-----\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}: \\n {doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the query and the relevant document contents\n",
    "\n",
    "combined_input = (\n",
    "    \"Here are some documents that might help answer the question: \"\n",
    "    + query\n",
    "    + \"\\n\\nRelevant Documents:\\n\"\n",
    "    + \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    + \"\\n\\nPlease provide an answer based only on the provided documents. If the answer is not found in the documents, respond with 'I'm not sure'.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = os.getenv(\"AZURE_OPENAI_API_VERSION\")  # Use the correct API version\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated Response ---\n",
      "Content only:\n",
      "An LLM (Language Model) evaluation refers to the process of assessing the performance and effectiveness of a language model. The evaluation methodology includes various metrics and approaches such as understanding language modeling metrics, entropy, cross entropy, bits-per-character and bits-per-byte, perplexity and its use cases, exact evaluation, functional correctness, similarity measurements against reference data, and the use of embedding. Additionally, AI can be used as a judge to rank models through comparative evaluation, although there are challenges associated with this process. \n",
      "\n",
      "Metrics like perplexity help interpret and understand the model's predictive performance, while exact evaluation and functional correctness ensure the accuracy and reliability of the model's outputs. Comparative evaluation and the use of embedding for similarity measurements are also important aspects of the evaluation methodology.\n",
      "\n",
      "In summary, LLM evaluation encompasses a range of metrics and methods to thoroughly evaluate language models from various perspectives.\n",
      "\n",
      "---\n",
      "\n",
      "This information has been compiled from Chapter 3: Evaluation Methodology in the provided documents.\n"
     ]
    }
   ],
   "source": [
    "# Define the messages for the model\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=combined_input),\n",
    "]\n",
    "\n",
    "# Invoke the model with the combined input\n",
    "result = model.invoke(messages)\n",
    "\n",
    "# Display the full result and content only\n",
    "print(\"\\n--- Generated Response ---\")\n",
    "# print(\"Full result:\")\n",
    "# print(result)\n",
    "print(\"Content only:\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. RAG conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the text files and the persistent directory\n",
    "current_dir = os.path.abspath(\"\")\n",
    "db_dir = os.path.join(current_dir, \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create openAI model\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = os.getenv(\"AZURE_OPENAI_API_VERSION\")  # Use the correct API version\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Give a chat history and the latest user question\"\n",
    "    \"which might reference context in the chat history\"\n",
    "    \"formulate a standalone question which can be understood\"\n",
    "    \"without the chat history. Do NOT answer the question, just\"\n",
    "    \"reformulate it if needed and otherwise return it as it is\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use\"\n",
    "    \"the following pieces of retrieved context to answer the\"\n",
    "    \"question. If you dont know the answer, just say that you\"\n",
    "    \"dont know. Use three sentences maximum and keep the answer\"\n",
    "    \"concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to simulate a continual chat\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            break\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(f\"AI: {result['answer']}\")\n",
    "        # Update the chat history\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(SystemMessage(content=result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n",
      "AI: Model distillation is a process where a smaller, more efficient model is trained to reproduce the behavior of a larger, more complex model. The knowledge from the large model is \"distilled\" into the smaller one, allowing it to achieve similar performance with reduced computational resources. This technique is often used to make models more suitable for deployment on devices with limited processing power.\n",
      "AI: April Dunford emphasizes the importance of understanding what best-fit prospects need to know to appreciate the unique value of your product. She suggests that your market insight should guide you in highlighting why your product is different and better than alternatives, which helps in building a strong sales pitch. Understanding your prospects' point of view is key to articulating your product’s unique market insight effectively.\n",
      "AI: Chip Huyen emphasizes that building AI products with defensibility is crucial for long-term success. She suggests that defensibility can be achieved through unique data assets, superior models, and effective deployment strategies that are hard for competitors to replicate. This approach ensures that the AI product remains competitive and valuable over time.\n",
      "AI: I'm sorry, but I don't have information on the specific chapter where Chip Huyen discusses product defensibility in her book \"AI Engineering.\"\n",
      "AI: I don't know the specific chapter where Chip Huyen discusses product defensibility in her book \"AI Engineering.\"\n",
      "AI: The chapters in Chip Huyen's book \"AI Engineering\" are as follows:\n",
      "\n",
      "1. Introduction\n",
      "2. Making of Foundation Models\n",
      "3. Evaluation Methods (Part 1)\n",
      "4. Evaluation Methods (Part 2)\n",
      "5. Prompt Engineering\n",
      "6. Context Construction\n",
      "7. Other chapters not specified in the provided excerpt\n",
      "10. AI Engineering Architecture and User Feedback\n",
      "Epilogue\n",
      "Index\n",
      "AI: I'm sorry, but I don't have information on the specific chapters of April Dunford's book on sales pitches.\n",
      "AI: I don't have the exact chapter titles from April Dunford's book on sales pitches.\n",
      "AI: Chip Huyen does not mention state space models in the provided excerpts from her book \"AI Engineering.\"\n",
      "AI: I don't have information on what Chip Huyen says about state space models.\n",
      "AI: The information I have includes some content from Chip Huyen's book \"AI Engineering\" and mentions of other works like \"Sales Pitch\" by April Dunford. However, my memory does not encompass a comprehensive list of books beyond the excerpts and context pieces provided to me.\n",
      "AI: Based on the provided excerpts, the books currently in my memory include:\n",
      "\n",
      "- \"AI Engineering\" by Chip Huyen\n",
      "- A book by April Dunford that includes content about sales pitches, market insights, and buyer's guides\n",
      "\n",
      "If you need further assistance or information from these books, feel free to ask!\n",
      "AI: Based on the excerpts, here are the books I currently have information from:\n",
      "\n",
      "- \"AI Engineering\" by Chip Huyen\n",
      "- \"Obviously Awesome\" by April Dunford\n",
      "\n",
      "If you need specific details or information from these books, please let me know!\n"
     ]
    }
   ],
   "source": [
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
